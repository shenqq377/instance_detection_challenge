{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instance Detection\n",
    "Training:\n",
    "1. Generate synthetic training data\n",
    "2. Train FasterRCNN on synthetic training data\n",
    "\n",
    "Testing:\n",
    "1. Test FasterRCNN on Scene images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Logger detectron2 (DEBUG)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import torch\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.data import build_detection_test_loader, DatasetCatalog, MetadataCatalog\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import hooks\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.layers.nms import batched_nms\n",
    "from detectron2.modeling import GeneralizedRCNNWithTTA\n",
    "from detectron2.structures import Boxes, BoxMode, Instances\n",
    "from detectron2.utils.logger import setup_logger\n",
    "\n",
    "# import custom nerfdet utilities\n",
    "from nerfdet.config import add_config\n",
    "from nerfdet.utils.visualizer import ColorMode, Visualizer\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "setup_logger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register InsDet Dataset for detectron2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def get_thing_classes(data_root, file_name=\"fg_object_id.json\"):\n",
    "    # get things classes and rename them from 0 to Number classes - 1\n",
    "\n",
    "    json_file = os.path.join(data_root, file_name)\n",
    "    thing_classes_dict = {}\n",
    "    with open(json_file, mode='r') as f:\n",
    "        fg_dict = json.load(f)\n",
    "\n",
    "    thing_classes = []  # a list of noun names\n",
    "    thing_classes_correspondence_dict = {}  # original noun class : relabeled noun class\n",
    "\n",
    "    for object_name in fg_dict.keys():\n",
    "        thing_classes_correspondence_dict[fg_dict[object_name]] = fg_dict[object_name]\n",
    "        thing_classes.append(object_name)\n",
    "\n",
    "    return thing_classes_correspondence_dict, thing_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root = os.path.join(os.path.dirname(os.getcwd()), 'NeRFDetExps/Data')\n",
    "anno_root = os.path.join(dataset_root, 'annotations')\n",
    "\n",
    "# train data\n",
    "train_path = os.path.join(dataset_root, 'train')\n",
    "train_json = os.path.join(anno_root, 'instances_train.json')\n",
    "register_coco_instances('coco_realDB_train', {}, train_json, train_path)\n",
    "\n",
    "# validation data\n",
    "val_path = os.path.join(dataset_root, 'val')\n",
    "val_json = os.path.join(anno_root, 'instances_val.json')\n",
    "register_coco_instances('coco_realDB_val', {}, val_json, val_path)\n",
    "\n",
    "# test data\n",
    "test_path = os.path.join(dataset_root, 'test_8')\n",
    "test_json = os.path.join(anno_root, 'instances_test_8.json')\n",
    "register_coco_instances('coco_realDB_test', {}, test_json, test_path)\n",
    "\n",
    "_, thing_classes = get_thing_classes(dataset_root)\n",
    "MetadataCatalog.get(\"coco_realDB_train\").thing_classes = thing_classes\n",
    "MetadataCatalog.get(\"coco_realDB_val\").thing_classes = thing_classes\n",
    "MetadataCatalog.get(\"coco_realDB_test\").thing_classes = thing_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# setup configs\n",
    "# FasterRCNN architecture\n",
    "yaml_f = 'faster_rcnn_R_50_FPN_3x.yaml'\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/{}\".format(yaml_f)))\n",
    "# load COCO pretrained weights\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/{}\".format(yaml_f))\n",
    "\n",
    "# ROI Heads\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 100\n",
    "\n",
    "# Solver\n",
    "cfg.SOLVER.IMS_PER_BATCH = 8\n",
    "cfg.SOLVER.BASE_LR = 0.002\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = 500\n",
    "cfg.TEST.EVAL_PERIOD = 500\n",
    "cfg.SOLVER.MAX_ITER = 2000\n",
    "\n",
    "# Input\n",
    "cfg.INPUT.CROP.ENABLED = True\n",
    "cfg.INPUT.MAX_SIZE_TRAIN = 1024\n",
    "cfg.INPUT.MAX_SIZE_TEST = 1024\n",
    "cfg.INPUT.MIN_SIZE_TRAIN = (768,)\n",
    "cfg.INPUT.MIN_SIZE_TEST = 0\n",
    "cfg.INPUT.MIN_SIZE_TRAIN_SAMPLING = 'choice'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on FasterRCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/15 17:04:51 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=101, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=400, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/15 17:05:00 d2.data.datasets.coco]: \u001b[0mLoading /home/SQQ/svid/NeRFDetExps/Data/annotations/instances_train.json takes 8.85 seconds.\n",
      "\u001b[32m[03/15 17:05:00 d2.data.datasets.coco]: \u001b[0mLoaded 19191 images in COCO format from /home/SQQ/svid/NeRFDetExps/Data/annotations/instances_train.json\n",
      "\u001b[32m[03/15 17:05:04 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 19191 images left.\n",
      "\u001b[32m[03/15 17:05:04 d2.data.build]: \u001b[0mDistribution of instances among all 100 categories:\n",
      "\u001b[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |\n",
      "|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|\n",
      "| 000_aveda_s.. | 5775         | 001_binder_.. | 5758         | 002_binder_.. | 5734         |\n",
      "| 003_bombik_.. | 5764         | 004_bonne_m.. | 5745         | 005_bonne_m.. | 5745         |\n",
      "| 006_bonne_m.. | 5757         | 007_costa_c.. | 5741         | 008_essenti.. | 5771         |\n",
      "| 009_garlic_.. | 5544         | 010_handcre.. | 5795         | 011_hb_calc.. | 5734         |\n",
      "| 012_hb_grap.. | 5761         | 013_hb_mari.. | 5787         | 014_hellman.. | 5753         |\n",
      "| 015_illy_bl.. | 5759         | 016_japanes.. | 5741         | 017_john_we.. | 5754         |\n",
      "| 018_kerasta.. | 5751         | 019_kiehls_.. | 5726         | 020_kiihne_.. | 5710         |\n",
      "| 021_kiihne_.. | 5777         | 022_lindor_.. | 5744         | 023_lindor_.. | 5734         |\n",
      "| 024_lush_mask | 5812         | 025_pasta_s.. | 5806         | 026_pasta_s.. | 5781         |\n",
      "|   027_pepsi   | 5771         | 028_portabl.. | 5757         | 029_selfile.. | 5737         |\n",
      "| 030_sour_le.. | 5740         | 031_sticky_.. | 5789         | 032_stridex.. | 5744         |\n",
      "| 033_thermos.. | 5732         | 034_thermos.. | 5746         | 035_thermos.. | 5707         |\n",
      "| 036_tragata.. | 5779         | 037_tulip_l.. | 5759         | 038_unichar.. | 5810         |\n",
      "| 039_vinda_t.. | 5774         | 040_wrigley.. | 5746         | 041_basebal.. | 5761         |\n",
      "| 042_basebal.. | 5793         | 043_bfe_fac.. | 5707         | 044_corgi_d.. | 5771         |\n",
      "| 045_dinosau.. | 5714         | 046_geo_mocha | 5739         | 047_geo_roa.. | 5766         |\n",
      "| 048_instant.. | 5828         | 049_instant.. | 5698         | 050_nabati_.. | 5775         |\n",
      "| 051_truffet.. | 5694         | 052_acnes_c.. | 5779         | 053_aveda_c.. | 5767         |\n",
      "| 054_banana_.. | 5811         | 055_candle_.. | 5806         | 056_china_p.. | 5754         |\n",
      "| 057_danisa_.. | 5785         | 058_effacla.. | 5767         | 059_evelom_.. | 5732         |\n",
      "| 060_glasses.. | 5839         | 061_handcre.. | 5741         | 062_handcre.. | 5267         |\n",
      "| 063_handcre.. | 5785         | 064_handcre.. | 5037         | 065_hr_serum  | 5861         |\n",
      "| 066_japanes.. | 5746         | 067_kerasta.. | 5745         | 068_kiehls_.. | 5806         |\n",
      "| 069_korean_.. | 5790         | 070_korean_.. | 5726         | 071_korean_.. | 5789         |\n",
      "| 072_korean_.. | 5760         | 073_loccita.. | 5814         | 074_marvis_.. | 5817         |\n",
      "| 075_mouse_t.. | 5759         | 076_oatly_c.. | 5786         | 077_oatly_o.. | 5791         |\n",
      "| 078_ousa_gr.. | 5807         | 079_polaroi.. | 5822         | 080_skinceu.. | 5800         |\n",
      "| 081_skinceu.. | 5730         | 082_skinceu.. | 5796         | 083_stapler.. | 5808         |\n",
      "| 084_stapler.. | 5765         | 085_sunscre.. | 5756         | 086_tempo_p.. | 5807         |\n",
      "| 087_thermos.. | 5751         | 088_uha_mat.. | 5799         | 089_urban_d.. | 5779         |\n",
      "| 090_vitaboo.. | 5771         | 091_waterco.. | 5736         | 092_youthlt.. | 5814         |\n",
      "| 093_daiso_m.. | 5709         | 094_kaneyo_.. | 5796         | 095_lays_ch.. | 5687         |\n",
      "| 096_lays_ch.. | 5733         | 097_lays_ch.. | 5718         | 098_lays_ch.. | 5764         |\n",
      "| 099_mug_blue  | 5691         |               |              |               |              |\n",
      "|     total     | 574995       |               |              |               |              |\u001b[0m\n",
      "\u001b[32m[03/15 17:05:05 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [RandomCrop(crop_type='relative_range', crop_size=[0.9, 0.9]), ResizeShortestEdge(short_edge_length=(768,), max_size=1024, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[03/15 17:05:05 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[03/15 17:05:05 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n",
      "\u001b[32m[03/15 17:05:05 d2.data.common]: \u001b[0mSerializing 19191 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/15 17:05:05 d2.data.common]: \u001b[0mSerialized dataset takes 80.49 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/15 17:05:06 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n",
      "\u001b[32m[03/15 17:05:08 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (101, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (101,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (400, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (400,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/15 17:05:10 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/SQQ/anaconda3/envs/svid/lib/python3.8/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484810403/work/aten/src/ATen/native/TensorShape.cpp:2894.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/15 17:05:53 d2.utils.events]: \u001b[0m eta: 0:26:12  iter: 19  total_loss: 5.756  loss_cls: 4.426  loss_box_reg: 0.7002  loss_rpn_cls: 0.439  loss_rpn_loc: 0.1803  time: 0.7933  data_time: 0.3549  lr: 3.9962e-05  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:06:08 d2.utils.events]: \u001b[0m eta: 0:25:47  iter: 39  total_loss: 4.689  loss_cls: 3.636  loss_box_reg: 0.7233  loss_rpn_cls: 0.1971  loss_rpn_loc: 0.1664  time: 0.7934  data_time: 0.3613  lr: 7.9922e-05  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:06:24 d2.utils.events]: \u001b[0m eta: 0:25:28  iter: 59  total_loss: 2.802  loss_cls: 1.747  loss_box_reg: 0.7512  loss_rpn_cls: 0.1246  loss_rpn_loc: 0.1739  time: 0.7849  data_time: 0.3391  lr: 0.00011988  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:06:40 d2.utils.events]: \u001b[0m eta: 0:25:16  iter: 79  total_loss: 2.608  loss_cls: 1.551  loss_box_reg: 0.7927  loss_rpn_cls: 0.09944  loss_rpn_loc: 0.1563  time: 0.7861  data_time: 0.3581  lr: 0.00015984  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:06:56 d2.utils.events]: \u001b[0m eta: 0:25:03  iter: 99  total_loss: 2.551  loss_cls: 1.482  loss_box_reg: 0.7974  loss_rpn_cls: 0.1016  loss_rpn_loc: 0.1614  time: 0.7915  data_time: 0.3759  lr: 0.0001998  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:07:11 d2.utils.events]: \u001b[0m eta: 0:24:44  iter: 119  total_loss: 2.517  loss_cls: 1.451  loss_box_reg: 0.8092  loss_rpn_cls: 0.08317  loss_rpn_loc: 0.1648  time: 0.7887  data_time: 0.3352  lr: 0.00023976  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:07:27 d2.utils.events]: \u001b[0m eta: 0:24:28  iter: 139  total_loss: 2.493  loss_cls: 1.437  loss_box_reg: 0.8167  loss_rpn_cls: 0.07269  loss_rpn_loc: 0.1487  time: 0.7876  data_time: 0.3421  lr: 0.00027972  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:07:43 d2.utils.events]: \u001b[0m eta: 0:24:17  iter: 159  total_loss: 2.489  loss_cls: 1.423  loss_box_reg: 0.8185  loss_rpn_cls: 0.08039  loss_rpn_loc: 0.1596  time: 0.7890  data_time: 0.3583  lr: 0.00031968  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:07:59 d2.utils.events]: \u001b[0m eta: 0:23:58  iter: 179  total_loss: 2.462  loss_cls: 1.414  loss_box_reg: 0.8236  loss_rpn_cls: 0.06989  loss_rpn_loc: 0.1491  time: 0.7892  data_time: 0.3517  lr: 0.00035964  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:08:15 d2.utils.events]: \u001b[0m eta: 0:23:43  iter: 199  total_loss: 2.432  loss_cls: 1.402  loss_box_reg: 0.8202  loss_rpn_cls: 0.06522  loss_rpn_loc: 0.1527  time: 0.7899  data_time: 0.3590  lr: 0.0003996  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:08:30 d2.utils.events]: \u001b[0m eta: 0:23:24  iter: 219  total_loss: 2.453  loss_cls: 1.395  loss_box_reg: 0.8267  loss_rpn_cls: 0.06979  loss_rpn_loc: 0.154  time: 0.7884  data_time: 0.3299  lr: 0.00043956  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:08:46 d2.utils.events]: \u001b[0m eta: 0:23:08  iter: 239  total_loss: 2.419  loss_cls: 1.381  loss_box_reg: 0.8324  loss_rpn_cls: 0.05524  loss_rpn_loc: 0.1434  time: 0.7888  data_time: 0.3487  lr: 0.00047952  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:09:02 d2.utils.events]: \u001b[0m eta: 0:22:51  iter: 259  total_loss: 2.412  loss_cls: 1.376  loss_box_reg: 0.8287  loss_rpn_cls: 0.05969  loss_rpn_loc: 0.1501  time: 0.7882  data_time: 0.3351  lr: 0.00051948  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:09:18 d2.utils.events]: \u001b[0m eta: 0:22:35  iter: 279  total_loss: 2.42  loss_cls: 1.369  loss_box_reg: 0.8303  loss_rpn_cls: 0.05646  loss_rpn_loc: 0.1619  time: 0.7884  data_time: 0.3519  lr: 0.00055944  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:09:34 d2.utils.events]: \u001b[0m eta: 0:22:19  iter: 299  total_loss: 2.378  loss_cls: 1.357  loss_box_reg: 0.8217  loss_rpn_cls: 0.06068  loss_rpn_loc: 0.1379  time: 0.7882  data_time: 0.3435  lr: 0.0005994  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:09:50 d2.utils.events]: \u001b[0m eta: 0:22:04  iter: 319  total_loss: 2.363  loss_cls: 1.343  loss_box_reg: 0.8116  loss_rpn_cls: 0.05087  loss_rpn_loc: 0.1497  time: 0.7904  data_time: 0.3786  lr: 0.00063936  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:10:06 d2.utils.events]: \u001b[0m eta: 0:21:47  iter: 339  total_loss: 2.337  loss_cls: 1.332  loss_box_reg: 0.8088  loss_rpn_cls: 0.05165  loss_rpn_loc: 0.146  time: 0.7898  data_time: 0.3337  lr: 0.00067932  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:10:21 d2.utils.events]: \u001b[0m eta: 0:21:31  iter: 359  total_loss: 2.311  loss_cls: 1.327  loss_box_reg: 0.8004  loss_rpn_cls: 0.04534  loss_rpn_loc: 0.1397  time: 0.7894  data_time: 0.3342  lr: 0.00071928  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:10:37 d2.utils.events]: \u001b[0m eta: 0:21:15  iter: 379  total_loss: 2.318  loss_cls: 1.312  loss_box_reg: 0.7893  loss_rpn_cls: 0.04719  loss_rpn_loc: 0.1422  time: 0.7899  data_time: 0.3544  lr: 0.00075924  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:10:53 d2.utils.events]: \u001b[0m eta: 0:21:00  iter: 399  total_loss: 2.253  loss_cls: 1.299  loss_box_reg: 0.7683  loss_rpn_cls: 0.04888  loss_rpn_loc: 0.1356  time: 0.7902  data_time: 0.3482  lr: 0.0007992  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:11:09 d2.utils.events]: \u001b[0m eta: 0:20:44  iter: 419  total_loss: 2.215  loss_cls: 1.276  loss_box_reg: 0.7323  loss_rpn_cls: 0.05168  loss_rpn_loc: 0.1407  time: 0.7901  data_time: 0.3404  lr: 0.00083916  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:11:25 d2.utils.events]: \u001b[0m eta: 0:20:28  iter: 439  total_loss: 2.104  loss_cls: 1.23  loss_box_reg: 0.6758  loss_rpn_cls: 0.04664  loss_rpn_loc: 0.1408  time: 0.7906  data_time: 0.3529  lr: 0.00087912  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:11:41 d2.utils.events]: \u001b[0m eta: 0:20:12  iter: 459  total_loss: 1.942  loss_cls: 1.185  loss_box_reg: 0.561  loss_rpn_cls: 0.0538  loss_rpn_loc: 0.1436  time: 0.7904  data_time: 0.3421  lr: 0.00091908  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:11:57 d2.utils.events]: \u001b[0m eta: 0:19:57  iter: 479  total_loss: 1.799  loss_cls: 1.118  loss_box_reg: 0.4789  loss_rpn_cls: 0.04972  loss_rpn_loc: 0.1451  time: 0.7916  data_time: 0.3788  lr: 0.00095904  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:12:17 d2.data.datasets.coco]: \u001b[0mLoading /home/SQQ/svid/NeRFDetExps/Data/annotations/instances_val.json takes 2.10 seconds.\n",
      "\u001b[32m[03/15 17:12:17 d2.data.datasets.coco]: \u001b[0mLoaded 6397 images in COCO format from /home/SQQ/svid/NeRFDetExps/Data/annotations/instances_val.json\n",
      "\u001b[32m[03/15 17:12:18 d2.data.build]: \u001b[0mDistribution of instances among all 100 categories:\n",
      "\u001b[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |\n",
      "|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|\n",
      "| 000_aveda_s.. | 1905         | 001_binder_.. | 1922         | 002_binder_.. | 1946         |\n",
      "| 003_bombik_.. | 1916         | 004_bonne_m.. | 1935         | 005_bonne_m.. | 1935         |\n",
      "| 006_bonne_m.. | 1923         | 007_costa_c.. | 1939         | 008_essenti.. | 1909         |\n",
      "| 009_garlic_.. | 1816         | 010_handcre.. | 1885         | 011_hb_calc.. | 1946         |\n",
      "| 012_hb_grap.. | 1919         | 013_hb_mari.. | 1893         | 014_hellman.. | 1927         |\n",
      "| 015_illy_bl.. | 1921         | 016_japanes.. | 1939         | 017_john_we.. | 1926         |\n",
      "| 018_kerasta.. | 1929         | 019_kiehls_.. | 1954         | 020_kiihne_.. | 1970         |\n",
      "| 021_kiihne_.. | 1903         | 022_lindor_.. | 1936         | 023_lindor_.. | 1946         |\n",
      "| 024_lush_mask | 1868         | 025_pasta_s.. | 1874         | 026_pasta_s.. | 1899         |\n",
      "|   027_pepsi   | 1909         | 028_portabl.. | 1923         | 029_selfile.. | 1943         |\n",
      "| 030_sour_le.. | 1940         | 031_sticky_.. | 1891         | 032_stridex.. | 1936         |\n",
      "| 033_thermos.. | 1948         | 034_thermos.. | 1934         | 035_thermos.. | 1973         |\n",
      "| 036_tragata.. | 1901         | 037_tulip_l.. | 1921         | 038_unichar.. | 1870         |\n",
      "| 039_vinda_t.. | 1906         | 040_wrigley.. | 1934         | 041_basebal.. | 1919         |\n",
      "| 042_basebal.. | 1887         | 043_bfe_fac.. | 1973         | 044_corgi_d.. | 1909         |\n",
      "| 045_dinosau.. | 1966         | 046_geo_mocha | 1941         | 047_geo_roa.. | 1914         |\n",
      "| 048_instant.. | 1852         | 049_instant.. | 1982         | 050_nabati_.. | 1905         |\n",
      "| 051_truffet.. | 1986         | 052_acnes_c.. | 1901         | 053_aveda_c.. | 1913         |\n",
      "| 054_banana_.. | 1869         | 055_candle_.. | 1874         | 056_china_p.. | 1926         |\n",
      "| 057_danisa_.. | 1895         | 058_effacla.. | 1913         | 059_evelom_.. | 1948         |\n",
      "| 060_glasses.. | 1841         | 061_handcre.. | 1939         | 062_handcre.. | 1773         |\n",
      "| 063_handcre.. | 1895         | 064_handcre.. | 1683         | 065_hr_serum  | 1819         |\n",
      "| 066_japanes.. | 1934         | 067_kerasta.. | 1935         | 068_kiehls_.. | 1874         |\n",
      "| 069_korean_.. | 1890         | 070_korean_.. | 1954         | 071_korean_.. | 1891         |\n",
      "| 072_korean_.. | 1920         | 073_loccita.. | 1866         | 074_marvis_.. | 1863         |\n",
      "| 075_mouse_t.. | 1921         | 076_oatly_c.. | 1894         | 077_oatly_o.. | 1889         |\n",
      "| 078_ousa_gr.. | 1873         | 079_polaroi.. | 1858         | 080_skinceu.. | 1880         |\n",
      "| 081_skinceu.. | 1950         | 082_skinceu.. | 1884         | 083_stapler.. | 1872         |\n",
      "| 084_stapler.. | 1915         | 085_sunscre.. | 1924         | 086_tempo_p.. | 1873         |\n",
      "| 087_thermos.. | 1929         | 088_uha_mat.. | 1881         | 089_urban_d.. | 1901         |\n",
      "| 090_vitaboo.. | 1909         | 091_waterco.. | 1944         | 092_youthlt.. | 1866         |\n",
      "| 093_daiso_m.. | 1971         | 094_kaneyo_.. | 1884         | 095_lays_ch.. | 1993         |\n",
      "| 096_lays_ch.. | 1947         | 097_lays_ch.. | 1962         | 098_lays_ch.. | 1916         |\n",
      "| 099_mug_blue  | 1989         |               |              |               |              |\n",
      "|     total     | 191085       |               |              |               |              |\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/15 17:12:18 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(0, 0), max_size=1024, sample_style='choice')]\n",
      "\u001b[32m[03/15 17:12:18 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n",
      "\u001b[32m[03/15 17:12:18 d2.data.common]: \u001b[0mSerializing 6397 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/15 17:12:18 d2.data.common]: \u001b[0mSerialized dataset takes 26.74 MiB\n",
      "\u001b[32m[03/15 17:12:20 d2.evaluation.evaluator]: \u001b[0mStart inference on 6397 batches\n",
      "\u001b[32m[03/15 17:12:20 d2.evaluation.evaluator]: \u001b[0mInference done 11/6397. Dataloading: 0.0072 s/iter. Inference: 0.0304 s/iter. Eval: 0.0003 s/iter. Total: 0.0379 s/iter. ETA=0:04:01\n",
      "\u001b[32m[03/15 17:12:25 d2.evaluation.evaluator]: \u001b[0mInference done 90/6397. Dataloading: 0.0366 s/iter. Inference: 0.0301 s/iter. Eval: 0.0003 s/iter. Total: 0.0671 s/iter. ETA=0:07:03\n",
      "\u001b[32m[03/15 17:12:31 d2.evaluation.evaluator]: \u001b[0mInference done 197/6397. Dataloading: 0.0253 s/iter. Inference: 0.0301 s/iter. Eval: 0.0003 s/iter. Total: 0.0558 s/iter. ETA=0:05:45\n",
      "\u001b[32m[03/15 17:12:36 d2.evaluation.evaluator]: \u001b[0mInference done 303/6397. Dataloading: 0.0223 s/iter. Inference: 0.0301 s/iter. Eval: 0.0003 s/iter. Total: 0.0527 s/iter. ETA=0:05:21\n",
      "\u001b[32m[03/15 17:12:41 d2.evaluation.evaluator]: \u001b[0mInference done 411/6397. Dataloading: 0.0206 s/iter. Inference: 0.0301 s/iter. Eval: 0.0003 s/iter. Total: 0.0511 s/iter. ETA=0:05:05\n",
      "\u001b[32m[03/15 17:12:46 d2.evaluation.evaluator]: \u001b[0mInference done 526/6397. Dataloading: 0.0190 s/iter. Inference: 0.0302 s/iter. Eval: 0.0003 s/iter. Total: 0.0494 s/iter. ETA=0:04:50\n",
      "\u001b[32m[03/15 17:12:51 d2.evaluation.evaluator]: \u001b[0mInference done 635/6397. Dataloading: 0.0184 s/iter. Inference: 0.0302 s/iter. Eval: 0.0003 s/iter. Total: 0.0489 s/iter. ETA=0:04:41\n",
      "\u001b[32m[03/15 17:12:56 d2.evaluation.evaluator]: \u001b[0mInference done 754/6397. Dataloading: 0.0173 s/iter. Inference: 0.0302 s/iter. Eval: 0.0003 s/iter. Total: 0.0478 s/iter. ETA=0:04:29\n",
      "\u001b[32m[03/15 17:13:01 d2.evaluation.evaluator]: \u001b[0mInference done 876/6397. Dataloading: 0.0163 s/iter. Inference: 0.0302 s/iter. Eval: 0.0003 s/iter. Total: 0.0469 s/iter. ETA=0:04:18\n",
      "\u001b[32m[03/15 17:13:06 d2.evaluation.evaluator]: \u001b[0mInference done 989/6397. Dataloading: 0.0160 s/iter. Inference: 0.0303 s/iter. Eval: 0.0003 s/iter. Total: 0.0466 s/iter. ETA=0:04:12\n",
      "\u001b[32m[03/15 17:13:11 d2.evaluation.evaluator]: \u001b[0mInference done 1110/6397. Dataloading: 0.0155 s/iter. Inference: 0.0302 s/iter. Eval: 0.0003 s/iter. Total: 0.0460 s/iter. ETA=0:04:03\n",
      "\u001b[32m[03/15 17:13:16 d2.evaluation.evaluator]: \u001b[0mInference done 1222/6397. Dataloading: 0.0153 s/iter. Inference: 0.0303 s/iter. Eval: 0.0003 s/iter. Total: 0.0459 s/iter. ETA=0:03:57\n",
      "\u001b[32m[03/15 17:13:21 d2.evaluation.evaluator]: \u001b[0mInference done 1330/6397. Dataloading: 0.0153 s/iter. Inference: 0.0304 s/iter. Eval: 0.0003 s/iter. Total: 0.0460 s/iter. ETA=0:03:53\n",
      "\u001b[32m[03/15 17:13:26 d2.evaluation.evaluator]: \u001b[0mInference done 1427/6397. Dataloading: 0.0157 s/iter. Inference: 0.0303 s/iter. Eval: 0.0003 s/iter. Total: 0.0464 s/iter. ETA=0:03:50\n",
      "\u001b[32m[03/15 17:13:31 d2.evaluation.evaluator]: \u001b[0mInference done 1542/6397. Dataloading: 0.0155 s/iter. Inference: 0.0303 s/iter. Eval: 0.0003 s/iter. Total: 0.0462 s/iter. ETA=0:03:44\n",
      "\u001b[32m[03/15 17:13:36 d2.evaluation.evaluator]: \u001b[0mInference done 1657/6397. Dataloading: 0.0153 s/iter. Inference: 0.0304 s/iter. Eval: 0.0003 s/iter. Total: 0.0460 s/iter. ETA=0:03:38\n",
      "\u001b[32m[03/15 17:13:41 d2.evaluation.evaluator]: \u001b[0mInference done 1773/6397. Dataloading: 0.0152 s/iter. Inference: 0.0303 s/iter. Eval: 0.0003 s/iter. Total: 0.0458 s/iter. ETA=0:03:31\n",
      "\u001b[32m[03/15 17:13:46 d2.evaluation.evaluator]: \u001b[0mInference done 1877/6397. Dataloading: 0.0153 s/iter. Inference: 0.0303 s/iter. Eval: 0.0003 s/iter. Total: 0.0460 s/iter. ETA=0:03:27\n",
      "\u001b[32m[03/15 17:13:51 d2.evaluation.evaluator]: \u001b[0mInference done 1986/6397. Dataloading: 0.0153 s/iter. Inference: 0.0303 s/iter. Eval: 0.0003 s/iter. Total: 0.0460 s/iter. ETA=0:03:22\n",
      "\u001b[32m[03/15 17:13:56 d2.evaluation.evaluator]: \u001b[0mInference done 2096/6397. Dataloading: 0.0153 s/iter. Inference: 0.0303 s/iter. Eval: 0.0003 s/iter. Total: 0.0460 s/iter. ETA=0:03:17\n",
      "\u001b[32m[03/15 17:14:01 d2.evaluation.evaluator]: \u001b[0mInference done 2213/6397. Dataloading: 0.0151 s/iter. Inference: 0.0303 s/iter. Eval: 0.0003 s/iter. Total: 0.0458 s/iter. ETA=0:03:11\n",
      "\u001b[32m[03/15 17:14:06 d2.evaluation.evaluator]: \u001b[0mInference done 2336/6397. Dataloading: 0.0149 s/iter. Inference: 0.0303 s/iter. Eval: 0.0003 s/iter. Total: 0.0455 s/iter. ETA=0:03:04\n",
      "\u001b[32m[03/15 17:14:11 d2.evaluation.evaluator]: \u001b[0mInference done 2468/6397. Dataloading: 0.0146 s/iter. Inference: 0.0302 s/iter. Eval: 0.0003 s/iter. Total: 0.0451 s/iter. ETA=0:02:57\n",
      "\u001b[32m[03/15 17:14:16 d2.evaluation.evaluator]: \u001b[0mInference done 2583/6397. Dataloading: 0.0145 s/iter. Inference: 0.0302 s/iter. Eval: 0.0003 s/iter. Total: 0.0451 s/iter. ETA=0:02:51\n",
      "\u001b[32m[03/15 17:14:21 d2.evaluation.evaluator]: \u001b[0mInference done 2688/6397. Dataloading: 0.0145 s/iter. Inference: 0.0303 s/iter. Eval: 0.0003 s/iter. Total: 0.0452 s/iter. ETA=0:02:47\n",
      "\u001b[32m[03/15 17:14:26 d2.evaluation.evaluator]: \u001b[0mInference done 2792/6397. Dataloading: 0.0144 s/iter. Inference: 0.0305 s/iter. Eval: 0.0003 s/iter. Total: 0.0453 s/iter. ETA=0:02:43\n",
      "\u001b[32m[03/15 17:14:32 d2.evaluation.evaluator]: \u001b[0mInference done 2921/6397. Dataloading: 0.0143 s/iter. Inference: 0.0305 s/iter. Eval: 0.0003 s/iter. Total: 0.0452 s/iter. ETA=0:02:37\n",
      "\u001b[32m[03/15 17:14:37 d2.evaluation.evaluator]: \u001b[0mInference done 3056/6397. Dataloading: 0.0141 s/iter. Inference: 0.0304 s/iter. Eval: 0.0003 s/iter. Total: 0.0448 s/iter. ETA=0:02:29\n",
      "\u001b[32m[03/15 17:14:42 d2.evaluation.evaluator]: \u001b[0mInference done 3191/6397. Dataloading: 0.0138 s/iter. Inference: 0.0304 s/iter. Eval: 0.0003 s/iter. Total: 0.0445 s/iter. ETA=0:02:22\n",
      "\u001b[32m[03/15 17:14:47 d2.evaluation.evaluator]: \u001b[0mInference done 3304/6397. Dataloading: 0.0138 s/iter. Inference: 0.0303 s/iter. Eval: 0.0003 s/iter. Total: 0.0445 s/iter. ETA=0:02:17\n",
      "\u001b[32m[03/15 17:14:52 d2.evaluation.evaluator]: \u001b[0mInference done 3434/6397. Dataloading: 0.0136 s/iter. Inference: 0.0303 s/iter. Eval: 0.0003 s/iter. Total: 0.0443 s/iter. ETA=0:02:11\n",
      "\u001b[32m[03/15 17:14:57 d2.evaluation.evaluator]: \u001b[0mInference done 3562/6397. Dataloading: 0.0135 s/iter. Inference: 0.0303 s/iter. Eval: 0.0003 s/iter. Total: 0.0441 s/iter. ETA=0:02:05\n",
      "\u001b[32m[03/15 17:15:02 d2.evaluation.evaluator]: \u001b[0mInference done 3687/6397. Dataloading: 0.0133 s/iter. Inference: 0.0303 s/iter. Eval: 0.0003 s/iter. Total: 0.0440 s/iter. ETA=0:01:59\n",
      "\u001b[32m[03/15 17:15:07 d2.evaluation.evaluator]: \u001b[0mInference done 3822/6397. Dataloading: 0.0131 s/iter. Inference: 0.0303 s/iter. Eval: 0.0003 s/iter. Total: 0.0437 s/iter. ETA=0:01:52\n",
      "\u001b[32m[03/15 17:15:12 d2.evaluation.evaluator]: \u001b[0mInference done 3958/6397. Dataloading: 0.0129 s/iter. Inference: 0.0302 s/iter. Eval: 0.0003 s/iter. Total: 0.0435 s/iter. ETA=0:01:46\n",
      "\u001b[32m[03/15 17:15:17 d2.evaluation.evaluator]: \u001b[0mInference done 4093/6397. Dataloading: 0.0127 s/iter. Inference: 0.0302 s/iter. Eval: 0.0003 s/iter. Total: 0.0433 s/iter. ETA=0:01:39\n",
      "\u001b[32m[03/15 17:15:22 d2.evaluation.evaluator]: \u001b[0mInference done 4228/6397. Dataloading: 0.0126 s/iter. Inference: 0.0302 s/iter. Eval: 0.0003 s/iter. Total: 0.0431 s/iter. ETA=0:01:33\n",
      "\u001b[32m[03/15 17:15:27 d2.evaluation.evaluator]: \u001b[0mInference done 4362/6397. Dataloading: 0.0124 s/iter. Inference: 0.0301 s/iter. Eval: 0.0003 s/iter. Total: 0.0429 s/iter. ETA=0:01:27\n",
      "\u001b[32m[03/15 17:15:32 d2.evaluation.evaluator]: \u001b[0mInference done 4471/6397. Dataloading: 0.0125 s/iter. Inference: 0.0301 s/iter. Eval: 0.0003 s/iter. Total: 0.0430 s/iter. ETA=0:01:22\n",
      "\u001b[32m[03/15 17:15:37 d2.evaluation.evaluator]: \u001b[0mInference done 4579/6397. Dataloading: 0.0126 s/iter. Inference: 0.0301 s/iter. Eval: 0.0003 s/iter. Total: 0.0431 s/iter. ETA=0:01:18\n",
      "\u001b[32m[03/15 17:15:42 d2.evaluation.evaluator]: \u001b[0mInference done 4710/6397. Dataloading: 0.0125 s/iter. Inference: 0.0301 s/iter. Eval: 0.0003 s/iter. Total: 0.0429 s/iter. ETA=0:01:12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/15 17:15:47 d2.evaluation.evaluator]: \u001b[0mInference done 4822/6397. Dataloading: 0.0125 s/iter. Inference: 0.0302 s/iter. Eval: 0.0003 s/iter. Total: 0.0430 s/iter. ETA=0:01:07\n",
      "\u001b[32m[03/15 17:15:52 d2.evaluation.evaluator]: \u001b[0mInference done 4907/6397. Dataloading: 0.0127 s/iter. Inference: 0.0302 s/iter. Eval: 0.0003 s/iter. Total: 0.0433 s/iter. ETA=0:01:04\n",
      "\u001b[32m[03/15 17:15:57 d2.evaluation.evaluator]: \u001b[0mInference done 5016/6397. Dataloading: 0.0128 s/iter. Inference: 0.0302 s/iter. Eval: 0.0003 s/iter. Total: 0.0433 s/iter. ETA=0:00:59\n",
      "\u001b[32m[03/15 17:16:02 d2.evaluation.evaluator]: \u001b[0mInference done 5131/6397. Dataloading: 0.0128 s/iter. Inference: 0.0302 s/iter. Eval: 0.0003 s/iter. Total: 0.0433 s/iter. ETA=0:00:54\n",
      "\u001b[32m[03/15 17:16:07 d2.evaluation.evaluator]: \u001b[0mInference done 5245/6397. Dataloading: 0.0128 s/iter. Inference: 0.0302 s/iter. Eval: 0.0003 s/iter. Total: 0.0433 s/iter. ETA=0:00:49\n",
      "\u001b[32m[03/15 17:16:12 d2.evaluation.evaluator]: \u001b[0mInference done 5374/6397. Dataloading: 0.0127 s/iter. Inference: 0.0302 s/iter. Eval: 0.0003 s/iter. Total: 0.0432 s/iter. ETA=0:00:44\n",
      "\u001b[32m[03/15 17:16:17 d2.evaluation.evaluator]: \u001b[0mInference done 5508/6397. Dataloading: 0.0126 s/iter. Inference: 0.0302 s/iter. Eval: 0.0003 s/iter. Total: 0.0431 s/iter. ETA=0:00:38\n",
      "\u001b[32m[03/15 17:16:22 d2.evaluation.evaluator]: \u001b[0mInference done 5643/6397. Dataloading: 0.0125 s/iter. Inference: 0.0301 s/iter. Eval: 0.0003 s/iter. Total: 0.0430 s/iter. ETA=0:00:32\n",
      "\u001b[32m[03/15 17:16:27 d2.evaluation.evaluator]: \u001b[0mInference done 5777/6397. Dataloading: 0.0124 s/iter. Inference: 0.0301 s/iter. Eval: 0.0003 s/iter. Total: 0.0428 s/iter. ETA=0:00:26\n",
      "\u001b[32m[03/15 17:16:32 d2.evaluation.evaluator]: \u001b[0mInference done 5914/6397. Dataloading: 0.0122 s/iter. Inference: 0.0301 s/iter. Eval: 0.0003 s/iter. Total: 0.0427 s/iter. ETA=0:00:20\n",
      "\u001b[32m[03/15 17:16:37 d2.evaluation.evaluator]: \u001b[0mInference done 6049/6397. Dataloading: 0.0121 s/iter. Inference: 0.0301 s/iter. Eval: 0.0003 s/iter. Total: 0.0426 s/iter. ETA=0:00:14\n",
      "\u001b[32m[03/15 17:16:42 d2.evaluation.evaluator]: \u001b[0mInference done 6184/6397. Dataloading: 0.0120 s/iter. Inference: 0.0301 s/iter. Eval: 0.0003 s/iter. Total: 0.0424 s/iter. ETA=0:00:09\n",
      "\u001b[32m[03/15 17:16:47 d2.evaluation.evaluator]: \u001b[0mInference done 6319/6397. Dataloading: 0.0119 s/iter. Inference: 0.0300 s/iter. Eval: 0.0003 s/iter. Total: 0.0423 s/iter. ETA=0:00:03\n",
      "\u001b[32m[03/15 17:16:50 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:04:30.163852 (0.042266 s / iter per device, on 1 devices)\n",
      "\u001b[32m[03/15 17:16:50 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:03:12 (0.030039 s / iter per device, on 1 devices)\n",
      "\u001b[32m[03/15 17:16:53 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[03/15 17:16:54 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./exp_on_FasterRCNN/inference/coco_instances_results.json\n",
      "\u001b[32m[03/15 17:16:56 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=1.84s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[03/15 17:16:58 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[03/15 17:17:20 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 21.32 seconds.\n",
      "\u001b[32m[03/15 17:17:20 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[03/15 17:17:24 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 3.52 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.186\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.260\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.229\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.078\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.211\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.497\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.277\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.350\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.350\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.158\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.396\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.647\n",
      "\u001b[32m[03/15 17:17:24 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 18.608 | 25.951 | 22.888 | 7.821 | 21.148 | 49.686 |\n",
      "\u001b[32m[03/15 17:17:24 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category                   | AP     | category                     | AP     | category                     | AP     |\n",
      "|:---------------------------|:-------|:-----------------------------|:-------|:-----------------------------|:-------|\n",
      "| 000_aveda_shampoo          | 18.284 | 001_binder_clips_median      | 31.234 | 002_binder_clips_small       | 3.704  |\n",
      "| 003_bombik_bucket          | 53.649 | 004_bonne_maman_blueberry    | 22.317 | 005_bonne_maman_raspberry    | 7.971  |\n",
      "| 006_bonne_maman_strawberry | 11.990 | 007_costa_caramel            | 19.173 | 008_essential_oil_bergamot   | 0.413  |\n",
      "| 009_garlic_toast_spread    | 0.000  | 010_handcream_avocado        | 8.439  | 011_hb_calcium               | 28.215 |\n",
      "| 012_hb_grapeseed           | 31.123 | 013_hb_marine_collagen       | 11.746 | 014_hellmanns_mayonnaise     | 3.408  |\n",
      "| 015_illy_blend             | 9.003  | 016_japanese_finger_cookies  | 41.891 | 017_john_west_canned_tuna    | 61.898 |\n",
      "| 018_kerastase_shampoo      | 2.069  | 019_kiehls_facial_cream      | 5.647  | 020_kiihne_balsamic          | 12.170 |\n",
      "| 021_kiihne_honey_mustard   | 34.826 | 022_lindor_matcha            | 39.506 | 023_lindor_salted_caramel    | 11.663 |\n",
      "| 024_lush_mask              | 57.970 | 025_pasta_sauce_black_pepper | 0.000  | 026_pasta_sauce_tomato       | 0.000  |\n",
      "| 027_pepsi                  | 24.707 | 028_portable_yogurt_machine  | 9.541  | 029_selfile_stick            | 10.461 |\n",
      "| 030_sour_lemon_drops       | 17.094 | 031_sticky_notes             | 21.961 | 032_stridex_green            | 10.340 |\n",
      "| 033_thermos_flask_cream    | 14.822 | 034_thermos_flask_muji       | 7.751  | 035_thermos_flask_sliver     | 6.563  |\n",
      "| 036_tragata_olive_oil      | 13.969 | 037_tulip_luncheon_meat      | 13.748 | 038_unicharm_cotton_pad      | 20.542 |\n",
      "| 039_vinda_tissue           | 38.074 | 040_wrigley_doublemint_gum   | 9.340  | 041_baseball_cap_black       | 33.636 |\n",
      "| 042_baseball_cap_pink      | 39.337 | 043_bfe_facial_mask          | 27.874 | 044_corgi_doll               | 51.136 |\n",
      "| 045_dinosaur_doll          | 53.209 | 046_geo_mocha                | 7.518  | 047_geo_roast_charcoal       | 14.436 |\n",
      "| 048_instant_noodle_black   | 12.541 | 049_instant_noodle_red       | 31.881 | 050_nabati_cheese_wafer      | 53.667 |\n",
      "| 051_truffettes             | 42.382 | 052_acnes_cream              | 5.913  | 053_aveda_conditioner        | 13.913 |\n",
      "| 054_banana_milk_drink      | 18.983 | 055_candle_beast             | 42.123 | 056_china_persimmon          | 64.564 |\n",
      "| 057_danisa_butter_cookies  | 10.774 | 058_effaclar_duo             | 0.143  | 059_evelom_cleanser          | 0.837  |\n",
      "| 060_glasses_box_blone      | 28.516 | 061_handcream_iris           | 0.046  | 062_handcream_lavender       | 0.026  |\n",
      "| 063_handcream_rosewater    | 12.554 | 064_handcream_summer_hill    | 0.000  | 065_hr_serum                 | 5.077  |\n",
      "| 066_japanese_chocolate     | 54.590 | 067_kerastase_hair_treatment | 0.000  | 068_kiehls_serum             | 1.830  |\n",
      "| 069_korean_beef_marinade   | 17.581 | 070_korean_doenjang          | 34.307 | 071_korean_gochujang         | 48.306 |\n",
      "| 072_korean_ssamjang        | 29.572 | 073_loccitane_soap           | 2.483  | 074_marvis_toothpaste_purple | 10.727 |\n",
      "| 075_mouse_thinkpad         | 33.036 | 076_oatly_chocolate          | 1.453  | 077_oatly_original           | 5.400  |\n",
      "| 078_ousa_grated_cheese     | 16.914 | 079_polaroid_film            | 1.547  | 080_skinceuticals_be         | 1.406  |\n",
      "| 081_skinceuticals_cf       | 0.590  | 082_skinceuticals_phyto      | 10.292 | 083_stapler_black            | 32.101 |\n",
      "| 084_stapler_blue           | 34.822 | 085_sunscreen_blue           | 0.324  | 086_tempo_pocket_tissue      | 0.244  |\n",
      "| 087_thermos_flask_purple   | 19.800 | 088_uha_matcha               | 17.450 | 089_urban_decay_spray        | 15.404 |\n",
      "| 090_vitaboost_multivitamin | 20.947 | 091_watercolor_penbox        | 0.216  | 092_youthlt_bilberry_complex | 15.590 |\n",
      "| 093_daiso_mod_remover      | 0.000  | 094_kaneyo_kitchen_bleach    | 5.346  | 095_lays_chip_bag_blue       | 9.362  |\n",
      "| 096_lays_chip_bag_green    | 19.557 | 097_lays_chip_tube_auburn    | 25.912 | 098_lays_chip_tube_green     | 41.324 |\n",
      "| 099_mug_blue               | 14.103 |                              |        |                              |        |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/15 17:17:26 d2.engine.defaults]: \u001b[0mEvaluation results for coco_realDB_val in csv format:\n",
      "\u001b[32m[03/15 17:17:26 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/15 17:17:26 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/15 17:17:26 d2.evaluation.testing]: \u001b[0mcopypaste: 18.6084,25.9511,22.8877,7.8207,21.1481,49.6861\n",
      "\u001b[32m[03/15 17:17:26 d2.utils.events]: \u001b[0m eta: 0:19:43  iter: 499  total_loss: 1.714  loss_cls: 1.056  loss_box_reg: 0.4455  loss_rpn_cls: 0.05187  loss_rpn_loc: 0.135  time: 0.7938  data_time: 0.4027  lr: 0.000999  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:17:42 d2.utils.events]: \u001b[0m eta: 0:19:27  iter: 519  total_loss: 1.575  loss_cls: 0.9639  loss_box_reg: 0.4208  loss_rpn_cls: 0.04819  loss_rpn_loc: 0.1433  time: 0.7935  data_time: 0.3480  lr: 0.001039  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:17:58 d2.utils.events]: \u001b[0m eta: 0:19:12  iter: 539  total_loss: 1.504  loss_cls: 0.8785  loss_box_reg: 0.409  loss_rpn_cls: 0.05593  loss_rpn_loc: 0.1536  time: 0.7943  data_time: 0.3730  lr: 0.0010789  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:18:14 d2.utils.events]: \u001b[0m eta: 0:18:56  iter: 559  total_loss: 1.391  loss_cls: 0.7925  loss_box_reg: 0.4019  loss_rpn_cls: 0.04579  loss_rpn_loc: 0.1408  time: 0.7938  data_time: 0.3398  lr: 0.0011189  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:18:28 d2.utils.events]: \u001b[0m eta: 0:18:38  iter: 579  total_loss: 1.3  loss_cls: 0.7072  loss_box_reg: 0.3902  loss_rpn_cls: 0.04373  loss_rpn_loc: 0.1445  time: 0.7919  data_time: 0.2981  lr: 0.0011588  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:18:44 d2.utils.events]: \u001b[0m eta: 0:18:23  iter: 599  total_loss: 1.268  loss_cls: 0.6677  loss_box_reg: 0.3916  loss_rpn_cls: 0.05262  loss_rpn_loc: 0.1463  time: 0.7919  data_time: 0.3522  lr: 0.0011988  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:19:00 d2.utils.events]: \u001b[0m eta: 0:18:06  iter: 619  total_loss: 1.153  loss_cls: 0.6072  loss_box_reg: 0.3671  loss_rpn_cls: 0.04519  loss_rpn_loc: 0.1342  time: 0.7913  data_time: 0.3297  lr: 0.0012388  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:19:16 d2.utils.events]: \u001b[0m eta: 0:17:51  iter: 639  total_loss: 1.151  loss_cls: 0.5873  loss_box_reg: 0.3811  loss_rpn_cls: 0.04973  loss_rpn_loc: 0.145  time: 0.7913  data_time: 0.3491  lr: 0.0012787  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:19:31 d2.utils.events]: \u001b[0m eta: 0:17:36  iter: 659  total_loss: 1.13  loss_cls: 0.5572  loss_box_reg: 0.3722  loss_rpn_cls: 0.04601  loss_rpn_loc: 0.1409  time: 0.7912  data_time: 0.3489  lr: 0.0013187  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:19:47 d2.utils.events]: \u001b[0m eta: 0:17:19  iter: 679  total_loss: 1.072  loss_cls: 0.5185  loss_box_reg: 0.3619  loss_rpn_cls: 0.04685  loss_rpn_loc: 0.1471  time: 0.7905  data_time: 0.3257  lr: 0.0013586  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:20:03 d2.utils.events]: \u001b[0m eta: 0:17:04  iter: 699  total_loss: 1.024  loss_cls: 0.4872  loss_box_reg: 0.353  loss_rpn_cls: 0.0373  loss_rpn_loc: 0.1416  time: 0.7904  data_time: 0.3427  lr: 0.0013986  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:20:18 d2.utils.events]: \u001b[0m eta: 0:16:48  iter: 719  total_loss: 1  loss_cls: 0.4767  loss_box_reg: 0.3484  loss_rpn_cls: 0.03676  loss_rpn_loc: 0.1313  time: 0.7904  data_time: 0.3496  lr: 0.0014386  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:20:34 d2.utils.events]: \u001b[0m eta: 0:16:32  iter: 739  total_loss: 0.9996  loss_cls: 0.4609  loss_box_reg: 0.3511  loss_rpn_cls: 0.03935  loss_rpn_loc: 0.1427  time: 0.7903  data_time: 0.3419  lr: 0.0014785  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:20:50 d2.utils.events]: \u001b[0m eta: 0:16:17  iter: 759  total_loss: 1.003  loss_cls: 0.4558  loss_box_reg: 0.3542  loss_rpn_cls: 0.05064  loss_rpn_loc: 0.1457  time: 0.7903  data_time: 0.3529  lr: 0.0015185  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:21:06 d2.utils.events]: \u001b[0m eta: 0:16:01  iter: 779  total_loss: 0.9545  loss_cls: 0.4374  loss_box_reg: 0.3528  loss_rpn_cls: 0.03746  loss_rpn_loc: 0.1299  time: 0.7905  data_time: 0.3569  lr: 0.0015584  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:21:21 d2.utils.events]: \u001b[0m eta: 0:15:44  iter: 799  total_loss: 0.9431  loss_cls: 0.43  loss_box_reg: 0.3416  loss_rpn_cls: 0.04286  loss_rpn_loc: 0.1302  time: 0.7901  data_time: 0.3350  lr: 0.0015984  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:21:37 d2.utils.events]: \u001b[0m eta: 0:15:28  iter: 819  total_loss: 0.919  loss_cls: 0.4052  loss_box_reg: 0.3365  loss_rpn_cls: 0.03718  loss_rpn_loc: 0.1353  time: 0.7898  data_time: 0.3363  lr: 0.0016384  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:21:52 d2.utils.events]: \u001b[0m eta: 0:15:12  iter: 839  total_loss: 0.9276  loss_cls: 0.4134  loss_box_reg: 0.3321  loss_rpn_cls: 0.03529  loss_rpn_loc: 0.1385  time: 0.7893  data_time: 0.3296  lr: 0.0016783  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:22:08 d2.utils.events]: \u001b[0m eta: 0:14:56  iter: 859  total_loss: 0.9081  loss_cls: 0.3977  loss_box_reg: 0.3331  loss_rpn_cls: 0.03899  loss_rpn_loc: 0.1424  time: 0.7886  data_time: 0.3151  lr: 0.0017183  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:22:23 d2.utils.events]: \u001b[0m eta: 0:14:40  iter: 879  total_loss: 0.8988  loss_cls: 0.3855  loss_box_reg: 0.3367  loss_rpn_cls: 0.03382  loss_rpn_loc: 0.1273  time: 0.7884  data_time: 0.3370  lr: 0.0017582  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:22:39 d2.utils.events]: \u001b[0m eta: 0:14:24  iter: 899  total_loss: 0.9094  loss_cls: 0.3917  loss_box_reg: 0.333  loss_rpn_cls: 0.03872  loss_rpn_loc: 0.1271  time: 0.7881  data_time: 0.3374  lr: 0.0017982  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:22:54 d2.utils.events]: \u001b[0m eta: 0:14:08  iter: 919  total_loss: 0.8629  loss_cls: 0.3759  loss_box_reg: 0.3207  loss_rpn_cls: 0.03355  loss_rpn_loc: 0.1291  time: 0.7875  data_time: 0.3145  lr: 0.0018382  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:23:10 d2.utils.events]: \u001b[0m eta: 0:13:52  iter: 939  total_loss: 0.8664  loss_cls: 0.3649  loss_box_reg: 0.3161  loss_rpn_cls: 0.03596  loss_rpn_loc: 0.1345  time: 0.7878  data_time: 0.3624  lr: 0.0018781  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:23:26 d2.utils.events]: \u001b[0m eta: 0:13:37  iter: 959  total_loss: 0.8773  loss_cls: 0.3681  loss_box_reg: 0.3195  loss_rpn_cls: 0.04409  loss_rpn_loc: 0.1414  time: 0.7883  data_time: 0.3675  lr: 0.0019181  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:23:43 d2.utils.events]: \u001b[0m eta: 0:13:22  iter: 979  total_loss: 0.8526  loss_cls: 0.3597  loss_box_reg: 0.3182  loss_rpn_cls: 0.0387  loss_rpn_loc: 0.1299  time: 0.7888  data_time: 0.3670  lr: 0.001958  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:24:00 d2.data.datasets.coco]: \u001b[0mLoaded 6397 images in COCO format from /home/SQQ/svid/NeRFDetExps/Data/annotations/instances_val.json\n",
      "\u001b[32m[03/15 17:24:01 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(0, 0), max_size=1024, sample_style='choice')]\n",
      "\u001b[32m[03/15 17:24:01 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n",
      "\u001b[32m[03/15 17:24:01 d2.data.common]: \u001b[0mSerializing 6397 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/15 17:24:01 d2.data.common]: \u001b[0mSerialized dataset takes 26.74 MiB\n",
      "\u001b[32m[03/15 17:24:03 d2.evaluation.evaluator]: \u001b[0mStart inference on 6397 batches\n",
      "\u001b[32m[03/15 17:24:04 d2.evaluation.evaluator]: \u001b[0mInference done 11/6397. Dataloading: 0.0072 s/iter. Inference: 0.0309 s/iter. Eval: 0.0003 s/iter. Total: 0.0383 s/iter. ETA=0:04:04\n",
      "\u001b[32m[03/15 17:24:09 d2.evaluation.evaluator]: \u001b[0mInference done 139/6397. Dataloading: 0.0086 s/iter. Inference: 0.0304 s/iter. Eval: 0.0003 s/iter. Total: 0.0392 s/iter. ETA=0:04:05\n",
      "\u001b[32m[03/15 17:24:14 d2.evaluation.evaluator]: \u001b[0mInference done 266/6397. Dataloading: 0.0086 s/iter. Inference: 0.0304 s/iter. Eval: 0.0003 s/iter. Total: 0.0394 s/iter. ETA=0:04:01\n",
      "\u001b[32m[03/15 17:24:19 d2.evaluation.evaluator]: \u001b[0mInference done 391/6397. Dataloading: 0.0087 s/iter. Inference: 0.0305 s/iter. Eval: 0.0003 s/iter. Total: 0.0396 s/iter. ETA=0:03:57\n",
      "\u001b[32m[03/15 17:24:24 d2.evaluation.evaluator]: \u001b[0mInference done 513/6397. Dataloading: 0.0089 s/iter. Inference: 0.0307 s/iter. Eval: 0.0003 s/iter. Total: 0.0399 s/iter. ETA=0:03:54\n",
      "\u001b[32m[03/15 17:24:29 d2.evaluation.evaluator]: \u001b[0mInference done 635/6397. Dataloading: 0.0090 s/iter. Inference: 0.0308 s/iter. Eval: 0.0003 s/iter. Total: 0.0402 s/iter. ETA=0:03:51\n",
      "\u001b[32m[03/15 17:24:34 d2.evaluation.evaluator]: \u001b[0mInference done 758/6397. Dataloading: 0.0089 s/iter. Inference: 0.0310 s/iter. Eval: 0.0003 s/iter. Total: 0.0403 s/iter. ETA=0:03:47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/15 17:24:39 d2.evaluation.evaluator]: \u001b[0mInference done 879/6397. Dataloading: 0.0090 s/iter. Inference: 0.0311 s/iter. Eval: 0.0003 s/iter. Total: 0.0404 s/iter. ETA=0:03:43\n",
      "\u001b[32m[03/15 17:24:44 d2.evaluation.evaluator]: \u001b[0mInference done 1000/6397. Dataloading: 0.0091 s/iter. Inference: 0.0311 s/iter. Eval: 0.0003 s/iter. Total: 0.0406 s/iter. ETA=0:03:38\n",
      "\u001b[32m[03/15 17:24:49 d2.evaluation.evaluator]: \u001b[0mInference done 1118/6397. Dataloading: 0.0096 s/iter. Inference: 0.0310 s/iter. Eval: 0.0003 s/iter. Total: 0.0409 s/iter. ETA=0:03:36\n",
      "\u001b[32m[03/15 17:24:54 d2.evaluation.evaluator]: \u001b[0mInference done 1254/6397. Dataloading: 0.0094 s/iter. Inference: 0.0307 s/iter. Eval: 0.0003 s/iter. Total: 0.0405 s/iter. ETA=0:03:28\n",
      "\u001b[32m[03/15 17:24:59 d2.evaluation.evaluator]: \u001b[0mInference done 1391/6397. Dataloading: 0.0092 s/iter. Inference: 0.0306 s/iter. Eval: 0.0003 s/iter. Total: 0.0401 s/iter. ETA=0:03:20\n",
      "\u001b[32m[03/15 17:25:04 d2.evaluation.evaluator]: \u001b[0mInference done 1526/6397. Dataloading: 0.0091 s/iter. Inference: 0.0304 s/iter. Eval: 0.0003 s/iter. Total: 0.0399 s/iter. ETA=0:03:14\n",
      "\u001b[32m[03/15 17:25:09 d2.evaluation.evaluator]: \u001b[0mInference done 1663/6397. Dataloading: 0.0090 s/iter. Inference: 0.0303 s/iter. Eval: 0.0003 s/iter. Total: 0.0396 s/iter. ETA=0:03:07\n",
      "\u001b[32m[03/15 17:25:14 d2.evaluation.evaluator]: \u001b[0mInference done 1799/6397. Dataloading: 0.0088 s/iter. Inference: 0.0302 s/iter. Eval: 0.0003 s/iter. Total: 0.0394 s/iter. ETA=0:03:01\n",
      "\u001b[32m[03/15 17:25:19 d2.evaluation.evaluator]: \u001b[0mInference done 1935/6397. Dataloading: 0.0087 s/iter. Inference: 0.0302 s/iter. Eval: 0.0003 s/iter. Total: 0.0392 s/iter. ETA=0:02:54\n",
      "\u001b[32m[03/15 17:25:24 d2.evaluation.evaluator]: \u001b[0mInference done 2072/6397. Dataloading: 0.0086 s/iter. Inference: 0.0301 s/iter. Eval: 0.0003 s/iter. Total: 0.0390 s/iter. ETA=0:02:48\n",
      "\u001b[32m[03/15 17:25:29 d2.evaluation.evaluator]: \u001b[0mInference done 2209/6397. Dataloading: 0.0085 s/iter. Inference: 0.0300 s/iter. Eval: 0.0003 s/iter. Total: 0.0389 s/iter. ETA=0:02:42\n",
      "\u001b[32m[03/15 17:25:34 d2.evaluation.evaluator]: \u001b[0mInference done 2344/6397. Dataloading: 0.0085 s/iter. Inference: 0.0300 s/iter. Eval: 0.0003 s/iter. Total: 0.0388 s/iter. ETA=0:02:37\n",
      "\u001b[32m[03/15 17:25:39 d2.evaluation.evaluator]: \u001b[0mInference done 2480/6397. Dataloading: 0.0084 s/iter. Inference: 0.0300 s/iter. Eval: 0.0003 s/iter. Total: 0.0387 s/iter. ETA=0:02:31\n",
      "\u001b[32m[03/15 17:25:44 d2.evaluation.evaluator]: \u001b[0mInference done 2614/6397. Dataloading: 0.0083 s/iter. Inference: 0.0300 s/iter. Eval: 0.0003 s/iter. Total: 0.0386 s/iter. ETA=0:02:26\n",
      "\u001b[32m[03/15 17:25:49 d2.evaluation.evaluator]: \u001b[0mInference done 2732/6397. Dataloading: 0.0085 s/iter. Inference: 0.0299 s/iter. Eval: 0.0003 s/iter. Total: 0.0388 s/iter. ETA=0:02:22\n",
      "\u001b[32m[03/15 17:25:54 d2.evaluation.evaluator]: \u001b[0mInference done 2868/6397. Dataloading: 0.0085 s/iter. Inference: 0.0299 s/iter. Eval: 0.0003 s/iter. Total: 0.0387 s/iter. ETA=0:02:16\n",
      "\u001b[32m[03/15 17:25:59 d2.evaluation.evaluator]: \u001b[0mInference done 3002/6397. Dataloading: 0.0084 s/iter. Inference: 0.0299 s/iter. Eval: 0.0003 s/iter. Total: 0.0386 s/iter. ETA=0:02:11\n",
      "\u001b[32m[03/15 17:26:04 d2.evaluation.evaluator]: \u001b[0mInference done 3136/6397. Dataloading: 0.0084 s/iter. Inference: 0.0299 s/iter. Eval: 0.0003 s/iter. Total: 0.0386 s/iter. ETA=0:02:05\n",
      "\u001b[32m[03/15 17:26:09 d2.evaluation.evaluator]: \u001b[0mInference done 3267/6397. Dataloading: 0.0084 s/iter. Inference: 0.0299 s/iter. Eval: 0.0003 s/iter. Total: 0.0386 s/iter. ETA=0:02:00\n",
      "\u001b[32m[03/15 17:26:14 d2.evaluation.evaluator]: \u001b[0mInference done 3401/6397. Dataloading: 0.0083 s/iter. Inference: 0.0299 s/iter. Eval: 0.0003 s/iter. Total: 0.0385 s/iter. ETA=0:01:55\n",
      "\u001b[32m[03/15 17:26:19 d2.evaluation.evaluator]: \u001b[0mInference done 3526/6397. Dataloading: 0.0083 s/iter. Inference: 0.0299 s/iter. Eval: 0.0003 s/iter. Total: 0.0386 s/iter. ETA=0:01:50\n",
      "\u001b[32m[03/15 17:26:24 d2.evaluation.evaluator]: \u001b[0mInference done 3658/6397. Dataloading: 0.0083 s/iter. Inference: 0.0299 s/iter. Eval: 0.0003 s/iter. Total: 0.0386 s/iter. ETA=0:01:45\n",
      "\u001b[32m[03/15 17:26:29 d2.evaluation.evaluator]: \u001b[0mInference done 3790/6397. Dataloading: 0.0083 s/iter. Inference: 0.0299 s/iter. Eval: 0.0003 s/iter. Total: 0.0386 s/iter. ETA=0:01:40\n",
      "\u001b[32m[03/15 17:26:34 d2.evaluation.evaluator]: \u001b[0mInference done 3924/6397. Dataloading: 0.0083 s/iter. Inference: 0.0299 s/iter. Eval: 0.0003 s/iter. Total: 0.0385 s/iter. ETA=0:01:35\n",
      "\u001b[32m[03/15 17:26:39 d2.evaluation.evaluator]: \u001b[0mInference done 4060/6397. Dataloading: 0.0082 s/iter. Inference: 0.0299 s/iter. Eval: 0.0003 s/iter. Total: 0.0385 s/iter. ETA=0:01:29\n",
      "\u001b[32m[03/15 17:26:44 d2.evaluation.evaluator]: \u001b[0mInference done 4196/6397. Dataloading: 0.0082 s/iter. Inference: 0.0299 s/iter. Eval: 0.0003 s/iter. Total: 0.0384 s/iter. ETA=0:01:24\n",
      "\u001b[32m[03/15 17:26:49 d2.evaluation.evaluator]: \u001b[0mInference done 4330/6397. Dataloading: 0.0082 s/iter. Inference: 0.0299 s/iter. Eval: 0.0003 s/iter. Total: 0.0384 s/iter. ETA=0:01:19\n",
      "\u001b[32m[03/15 17:26:54 d2.evaluation.evaluator]: \u001b[0mInference done 4466/6397. Dataloading: 0.0082 s/iter. Inference: 0.0299 s/iter. Eval: 0.0003 s/iter. Total: 0.0383 s/iter. ETA=0:01:14\n",
      "\u001b[32m[03/15 17:26:59 d2.evaluation.evaluator]: \u001b[0mInference done 4602/6397. Dataloading: 0.0081 s/iter. Inference: 0.0298 s/iter. Eval: 0.0003 s/iter. Total: 0.0383 s/iter. ETA=0:01:08\n",
      "\u001b[32m[03/15 17:27:04 d2.evaluation.evaluator]: \u001b[0mInference done 4726/6397. Dataloading: 0.0082 s/iter. Inference: 0.0298 s/iter. Eval: 0.0003 s/iter. Total: 0.0384 s/iter. ETA=0:01:04\n",
      "\u001b[32m[03/15 17:27:09 d2.evaluation.evaluator]: \u001b[0mInference done 4863/6397. Dataloading: 0.0082 s/iter. Inference: 0.0298 s/iter. Eval: 0.0003 s/iter. Total: 0.0383 s/iter. ETA=0:00:58\n",
      "\u001b[32m[03/15 17:27:14 d2.evaluation.evaluator]: \u001b[0mInference done 5000/6397. Dataloading: 0.0082 s/iter. Inference: 0.0298 s/iter. Eval: 0.0003 s/iter. Total: 0.0383 s/iter. ETA=0:00:53\n",
      "\u001b[32m[03/15 17:27:19 d2.evaluation.evaluator]: \u001b[0mInference done 5137/6397. Dataloading: 0.0081 s/iter. Inference: 0.0298 s/iter. Eval: 0.0003 s/iter. Total: 0.0382 s/iter. ETA=0:00:48\n",
      "\u001b[32m[03/15 17:27:24 d2.evaluation.evaluator]: \u001b[0mInference done 5274/6397. Dataloading: 0.0081 s/iter. Inference: 0.0297 s/iter. Eval: 0.0003 s/iter. Total: 0.0382 s/iter. ETA=0:00:42\n",
      "\u001b[32m[03/15 17:27:29 d2.evaluation.evaluator]: \u001b[0mInference done 5410/6397. Dataloading: 0.0081 s/iter. Inference: 0.0297 s/iter. Eval: 0.0003 s/iter. Total: 0.0381 s/iter. ETA=0:00:37\n",
      "\u001b[32m[03/15 17:27:35 d2.evaluation.evaluator]: \u001b[0mInference done 5546/6397. Dataloading: 0.0081 s/iter. Inference: 0.0297 s/iter. Eval: 0.0003 s/iter. Total: 0.0381 s/iter. ETA=0:00:32\n",
      "\u001b[32m[03/15 17:27:40 d2.evaluation.evaluator]: \u001b[0mInference done 5681/6397. Dataloading: 0.0081 s/iter. Inference: 0.0297 s/iter. Eval: 0.0003 s/iter. Total: 0.0381 s/iter. ETA=0:00:27\n",
      "\u001b[32m[03/15 17:27:45 d2.evaluation.evaluator]: \u001b[0mInference done 5817/6397. Dataloading: 0.0081 s/iter. Inference: 0.0297 s/iter. Eval: 0.0003 s/iter. Total: 0.0381 s/iter. ETA=0:00:22\n",
      "\u001b[32m[03/15 17:27:50 d2.evaluation.evaluator]: \u001b[0mInference done 5947/6397. Dataloading: 0.0081 s/iter. Inference: 0.0297 s/iter. Eval: 0.0003 s/iter. Total: 0.0381 s/iter. ETA=0:00:17\n",
      "\u001b[32m[03/15 17:27:55 d2.evaluation.evaluator]: \u001b[0mInference done 6072/6397. Dataloading: 0.0081 s/iter. Inference: 0.0297 s/iter. Eval: 0.0003 s/iter. Total: 0.0381 s/iter. ETA=0:00:12\n",
      "\u001b[32m[03/15 17:28:00 d2.evaluation.evaluator]: \u001b[0mInference done 6197/6397. Dataloading: 0.0081 s/iter. Inference: 0.0298 s/iter. Eval: 0.0003 s/iter. Total: 0.0382 s/iter. ETA=0:00:07\n",
      "\u001b[32m[03/15 17:28:05 d2.evaluation.evaluator]: \u001b[0mInference done 6325/6397. Dataloading: 0.0081 s/iter. Inference: 0.0298 s/iter. Eval: 0.0003 s/iter. Total: 0.0382 s/iter. ETA=0:00:02\n",
      "\u001b[32m[03/15 17:28:07 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:04:04.041839 (0.038179 s / iter per device, on 1 devices)\n",
      "\u001b[32m[03/15 17:28:07 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:03:10 (0.029770 s / iter per device, on 1 devices)\n",
      "\u001b[32m[03/15 17:28:11 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[03/15 17:28:12 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./exp_on_FasterRCNN/inference/coco_instances_results.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/15 17:28:15 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=2.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[03/15 17:28:17 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[03/15 17:28:40 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 22.68 seconds.\n",
      "\u001b[32m[03/15 17:28:40 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[03/15 17:28:44 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 3.53 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.617\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.842\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.751\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.501\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.668\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.797\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.599\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.691\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.691\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.601\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.730\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.830\n",
      "\u001b[32m[03/15 17:28:44 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 61.667 | 84.178 | 75.149 | 50.109 | 66.847 | 79.716 |\n",
      "\u001b[32m[03/15 17:28:44 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category                   | AP     | category                     | AP     | category                     | AP     |\n",
      "|:---------------------------|:-------|:-----------------------------|:-------|:-----------------------------|:-------|\n",
      "| 000_aveda_shampoo          | 63.933 | 001_binder_clips_median      | 75.309 | 002_binder_clips_small       | 63.426 |\n",
      "| 003_bombik_bucket          | 75.722 | 004_bonne_maman_blueberry    | 63.354 | 005_bonne_maman_raspberry    | 29.996 |\n",
      "| 006_bonne_maman_strawberry | 30.244 | 007_costa_caramel            | 67.485 | 008_essential_oil_bergamot   | 55.970 |\n",
      "| 009_garlic_toast_spread    | 38.856 | 010_handcream_avocado        | 43.272 | 011_hb_calcium               | 67.776 |\n",
      "| 012_hb_grapeseed           | 72.913 | 013_hb_marine_collagen       | 57.697 | 014_hellmanns_mayonnaise     | 69.844 |\n",
      "| 015_illy_blend             | 62.700 | 016_japanese_finger_cookies  | 78.031 | 017_john_west_canned_tuna    | 62.725 |\n",
      "| 018_kerastase_shampoo      | 58.304 | 019_kiehls_facial_cream      | 63.757 | 020_kiihne_balsamic          | 55.326 |\n",
      "| 021_kiihne_honey_mustard   | 62.212 | 022_lindor_matcha            | 67.666 | 023_lindor_salted_caramel    | 73.499 |\n",
      "| 024_lush_mask              | 77.718 | 025_pasta_sauce_black_pepper | 38.780 | 026_pasta_sauce_tomato       | 29.037 |\n",
      "| 027_pepsi                  | 78.609 | 028_portable_yogurt_machine  | 62.310 | 029_selfile_stick            | 60.441 |\n",
      "| 030_sour_lemon_drops       | 69.674 | 031_sticky_notes             | 66.815 | 032_stridex_green            | 63.771 |\n",
      "| 033_thermos_flask_cream    | 68.558 | 034_thermos_flask_muji       | 68.445 | 035_thermos_flask_sliver     | 66.553 |\n",
      "| 036_tragata_olive_oil      | 58.316 | 037_tulip_luncheon_meat      | 60.573 | 038_unicharm_cotton_pad      | 69.763 |\n",
      "| 039_vinda_tissue           | 55.425 | 040_wrigley_doublemint_gum   | 64.094 | 041_baseball_cap_black       | 70.640 |\n",
      "| 042_baseball_cap_pink      | 76.258 | 043_bfe_facial_mask          | 68.728 | 044_corgi_doll               | 63.533 |\n",
      "| 045_dinosaur_doll          | 74.396 | 046_geo_mocha                | 64.708 | 047_geo_roast_charcoal       | 67.257 |\n",
      "| 048_instant_noodle_black   | 63.762 | 049_instant_noodle_red       | 75.466 | 050_nabati_cheese_wafer      | 75.774 |\n",
      "| 051_truffettes             | 69.072 | 052_acnes_cream              | 57.089 | 053_aveda_conditioner        | 60.179 |\n",
      "| 054_banana_milk_drink      | 70.600 | 055_candle_beast             | 79.066 | 056_china_persimmon          | 79.363 |\n",
      "| 057_danisa_butter_cookies  | 62.122 | 058_effaclar_duo             | 38.634 | 059_evelom_cleanser          | 46.550 |\n",
      "| 060_glasses_box_blone      | 69.400 | 061_handcream_iris           | 35.284 | 062_handcream_lavender       | 28.620 |\n",
      "| 063_handcream_rosewater    | 54.941 | 064_handcream_summer_hill    | 30.898 | 065_hr_serum                 | 62.419 |\n",
      "| 066_japanese_chocolate     | 80.756 | 067_kerastase_hair_treatment | 51.797 | 068_kiehls_serum             | 52.295 |\n",
      "| 069_korean_beef_marinade   | 61.301 | 070_korean_doenjang          | 76.789 | 071_korean_gochujang         | 78.805 |\n",
      "| 072_korean_ssamjang        | 70.680 | 073_loccitane_soap           | 64.059 | 074_marvis_toothpaste_purple | 49.978 |\n",
      "| 075_mouse_thinkpad         | 63.933 | 076_oatly_chocolate          | 59.940 | 077_oatly_original           | 62.314 |\n",
      "| 078_ousa_grated_cheese     | 73.477 | 079_polaroid_film            | 70.344 | 080_skinceuticals_be         | 69.580 |\n",
      "| 081_skinceuticals_cf       | 39.640 | 082_skinceuticals_phyto      | 57.989 | 083_stapler_black            | 59.819 |\n",
      "| 084_stapler_blue           | 70.636 | 085_sunscreen_blue           | 44.969 | 086_tempo_pocket_tissue      | 54.739 |\n",
      "| 087_thermos_flask_purple   | 74.624 | 088_uha_matcha               | 61.732 | 089_urban_decay_spray        | 58.168 |\n",
      "| 090_vitaboost_multivitamin | 61.762 | 091_watercolor_penbox        | 50.965 | 092_youthlt_bilberry_complex | 59.752 |\n",
      "| 093_daiso_mod_remover      | 50.116 | 094_kaneyo_kitchen_bleach    | 55.246 | 095_lays_chip_bag_blue       | 58.590 |\n",
      "| 096_lays_chip_bag_green    | 59.280 | 097_lays_chip_tube_auburn    | 72.598 | 098_lays_chip_tube_green     | 75.613 |\n",
      "| 099_mug_blue               | 50.789 |                              |        |                              |        |\n",
      "\u001b[32m[03/15 17:28:46 d2.engine.defaults]: \u001b[0mEvaluation results for coco_realDB_val in csv format:\n",
      "\u001b[32m[03/15 17:28:46 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/15 17:28:46 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/15 17:28:46 d2.evaluation.testing]: \u001b[0mcopypaste: 61.6674,84.1779,75.1490,50.1091,66.8466,79.7158\n",
      "\u001b[32m[03/15 17:28:46 d2.utils.events]: \u001b[0m eta: 0:13:07  iter: 999  total_loss: 0.8635  loss_cls: 0.3574  loss_box_reg: 0.323  loss_rpn_cls: 0.03893  loss_rpn_loc: 0.1266  time: 0.7896  data_time: 0.3863  lr: 0.001998  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:29:02 d2.utils.events]: \u001b[0m eta: 0:12:51  iter: 1019  total_loss: 0.826  loss_cls: 0.3347  loss_box_reg: 0.3177  loss_rpn_cls: 0.04007  loss_rpn_loc: 0.1322  time: 0.7898  data_time: 0.3573  lr: 0.002  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:29:18 d2.utils.events]: \u001b[0m eta: 0:12:35  iter: 1039  total_loss: 0.83  loss_cls: 0.3422  loss_box_reg: 0.3169  loss_rpn_cls: 0.03681  loss_rpn_loc: 0.1477  time: 0.7897  data_time: 0.3450  lr: 0.002  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:29:34 d2.utils.events]: \u001b[0m eta: 0:12:20  iter: 1059  total_loss: 0.8198  loss_cls: 0.3387  loss_box_reg: 0.3087  loss_rpn_cls: 0.03418  loss_rpn_loc: 0.1324  time: 0.7900  data_time: 0.3656  lr: 0.002  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:29:50 d2.utils.events]: \u001b[0m eta: 0:12:04  iter: 1079  total_loss: 0.7801  loss_cls: 0.3312  loss_box_reg: 0.2977  loss_rpn_cls: 0.03775  loss_rpn_loc: 0.1344  time: 0.7904  data_time: 0.3717  lr: 0.002  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:30:07 d2.utils.events]: \u001b[0m eta: 0:11:48  iter: 1099  total_loss: 0.7967  loss_cls: 0.3254  loss_box_reg: 0.3033  loss_rpn_cls: 0.03356  loss_rpn_loc: 0.13  time: 0.7907  data_time: 0.3595  lr: 0.002  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:30:22 d2.utils.events]: \u001b[0m eta: 0:11:32  iter: 1119  total_loss: 0.7758  loss_cls: 0.3119  loss_box_reg: 0.3076  loss_rpn_cls: 0.03655  loss_rpn_loc: 0.1269  time: 0.7906  data_time: 0.3400  lr: 0.002  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:30:39 d2.utils.events]: \u001b[0m eta: 0:11:17  iter: 1139  total_loss: 0.83  loss_cls: 0.3388  loss_box_reg: 0.3159  loss_rpn_cls: 0.04278  loss_rpn_loc: 0.1355  time: 0.7910  data_time: 0.3703  lr: 0.002  max_mem: 7021M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/15 17:30:54 d2.utils.events]: \u001b[0m eta: 0:11:01  iter: 1159  total_loss: 0.7923  loss_cls: 0.3262  loss_box_reg: 0.3013  loss_rpn_cls: 0.03613  loss_rpn_loc: 0.1261  time: 0.7911  data_time: 0.3520  lr: 0.002  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:31:11 d2.utils.events]: \u001b[0m eta: 0:10:45  iter: 1179  total_loss: 0.7714  loss_cls: 0.3039  loss_box_reg: 0.2946  loss_rpn_cls: 0.0334  loss_rpn_loc: 0.1382  time: 0.7914  data_time: 0.3667  lr: 0.002  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:31:26 d2.utils.events]: \u001b[0m eta: 0:10:29  iter: 1199  total_loss: 0.7805  loss_cls: 0.3169  loss_box_reg: 0.2962  loss_rpn_cls: 0.03538  loss_rpn_loc: 0.1313  time: 0.7913  data_time: 0.3401  lr: 0.002  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:31:42 d2.utils.events]: \u001b[0m eta: 0:10:14  iter: 1219  total_loss: 0.7534  loss_cls: 0.3123  loss_box_reg: 0.2884  loss_rpn_cls: 0.03067  loss_rpn_loc: 0.1222  time: 0.7911  data_time: 0.3313  lr: 0.002  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:31:58 d2.utils.events]: \u001b[0m eta: 0:09:57  iter: 1239  total_loss: 0.751  loss_cls: 0.2971  loss_box_reg: 0.2924  loss_rpn_cls: 0.03476  loss_rpn_loc: 0.1205  time: 0.7908  data_time: 0.3295  lr: 0.002  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:32:13 d2.utils.events]: \u001b[0m eta: 0:09:41  iter: 1259  total_loss: 0.7564  loss_cls: 0.3028  loss_box_reg: 0.2881  loss_rpn_cls: 0.03213  loss_rpn_loc: 0.1172  time: 0.7906  data_time: 0.3261  lr: 0.002  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:32:29 d2.utils.events]: \u001b[0m eta: 0:09:25  iter: 1279  total_loss: 0.7635  loss_cls: 0.3023  loss_box_reg: 0.2897  loss_rpn_cls: 0.04086  loss_rpn_loc: 0.1235  time: 0.7905  data_time: 0.3400  lr: 0.002  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:32:44 d2.utils.events]: \u001b[0m eta: 0:09:10  iter: 1299  total_loss: 0.7486  loss_cls: 0.2918  loss_box_reg: 0.2835  loss_rpn_cls: 0.03675  loss_rpn_loc: 0.1345  time: 0.7904  data_time: 0.3350  lr: 0.002  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:33:00 d2.utils.events]: \u001b[0m eta: 0:08:54  iter: 1319  total_loss: 0.7541  loss_cls: 0.3064  loss_box_reg: 0.2867  loss_rpn_cls: 0.03901  loss_rpn_loc: 0.1224  time: 0.7905  data_time: 0.3512  lr: 0.002  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:33:16 d2.utils.events]: \u001b[0m eta: 0:08:38  iter: 1339  total_loss: 0.7249  loss_cls: 0.2845  loss_box_reg: 0.2776  loss_rpn_cls: 0.03794  loss_rpn_loc: 0.1254  time: 0.7902  data_time: 0.3227  lr: 0.002  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:33:32 d2.utils.events]: \u001b[0m eta: 0:08:22  iter: 1359  total_loss: 0.7534  loss_cls: 0.3055  loss_box_reg: 0.2891  loss_rpn_cls: 0.03532  loss_rpn_loc: 0.1247  time: 0.7901  data_time: 0.3379  lr: 0.002  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:33:47 d2.utils.events]: \u001b[0m eta: 0:08:07  iter: 1379  total_loss: 0.7259  loss_cls: 0.2852  loss_box_reg: 0.277  loss_rpn_cls: 0.0343  loss_rpn_loc: 0.1284  time: 0.7902  data_time: 0.3487  lr: 0.002  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:34:03 d2.utils.events]: \u001b[0m eta: 0:07:51  iter: 1399  total_loss: 0.7317  loss_cls: 0.2883  loss_box_reg: 0.2774  loss_rpn_cls: 0.0332  loss_rpn_loc: 0.1281  time: 0.7900  data_time: 0.3322  lr: 0.002  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:34:19 d2.utils.events]: \u001b[0m eta: 0:07:35  iter: 1419  total_loss: 0.7357  loss_cls: 0.2862  loss_box_reg: 0.2824  loss_rpn_cls: 0.03228  loss_rpn_loc: 0.1324  time: 0.7898  data_time: 0.3297  lr: 0.002  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:34:34 d2.utils.events]: \u001b[0m eta: 0:07:20  iter: 1439  total_loss: 0.7409  loss_cls: 0.2921  loss_box_reg: 0.281  loss_rpn_cls: 0.03519  loss_rpn_loc: 0.1237  time: 0.7898  data_time: 0.3419  lr: 0.002  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:34:50 d2.utils.events]: \u001b[0m eta: 0:07:04  iter: 1459  total_loss: 0.7272  loss_cls: 0.2818  loss_box_reg: 0.2782  loss_rpn_cls: 0.03563  loss_rpn_loc: 0.1228  time: 0.7896  data_time: 0.3284  lr: 0.002  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:35:06 d2.utils.events]: \u001b[0m eta: 0:06:48  iter: 1479  total_loss: 0.7184  loss_cls: 0.2841  loss_box_reg: 0.2807  loss_rpn_cls: 0.03167  loss_rpn_loc: 0.126  time: 0.7896  data_time: 0.3451  lr: 0.002  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:35:23 d2.data.datasets.coco]: \u001b[0mLoaded 6397 images in COCO format from /home/SQQ/svid/NeRFDetExps/Data/annotations/instances_val.json\n",
      "\u001b[32m[03/15 17:35:24 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(0, 0), max_size=1024, sample_style='choice')]\n",
      "\u001b[32m[03/15 17:35:24 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n",
      "\u001b[32m[03/15 17:35:24 d2.data.common]: \u001b[0mSerializing 6397 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/15 17:35:24 d2.data.common]: \u001b[0mSerialized dataset takes 26.74 MiB\n",
      "\u001b[32m[03/15 17:35:26 d2.evaluation.evaluator]: \u001b[0mStart inference on 6397 batches\n",
      "\u001b[32m[03/15 17:35:26 d2.evaluation.evaluator]: \u001b[0mInference done 11/6397. Dataloading: 0.0062 s/iter. Inference: 0.0291 s/iter. Eval: 0.0002 s/iter. Total: 0.0355 s/iter. ETA=0:03:46\n",
      "\u001b[32m[03/15 17:35:31 d2.evaluation.evaluator]: \u001b[0mInference done 148/6397. Dataloading: 0.0071 s/iter. Inference: 0.0291 s/iter. Eval: 0.0002 s/iter. Total: 0.0365 s/iter. ETA=0:03:48\n",
      "\u001b[32m[03/15 17:35:36 d2.evaluation.evaluator]: \u001b[0mInference done 284/6397. Dataloading: 0.0072 s/iter. Inference: 0.0292 s/iter. Eval: 0.0002 s/iter. Total: 0.0367 s/iter. ETA=0:03:44\n",
      "\u001b[32m[03/15 17:35:41 d2.evaluation.evaluator]: \u001b[0mInference done 409/6397. Dataloading: 0.0077 s/iter. Inference: 0.0297 s/iter. Eval: 0.0002 s/iter. Total: 0.0377 s/iter. ETA=0:03:45\n",
      "\u001b[32m[03/15 17:35:46 d2.evaluation.evaluator]: \u001b[0mInference done 538/6397. Dataloading: 0.0078 s/iter. Inference: 0.0299 s/iter. Eval: 0.0002 s/iter. Total: 0.0380 s/iter. ETA=0:03:42\n",
      "\u001b[32m[03/15 17:35:51 d2.evaluation.evaluator]: \u001b[0mInference done 664/6397. Dataloading: 0.0079 s/iter. Inference: 0.0301 s/iter. Eval: 0.0003 s/iter. Total: 0.0384 s/iter. ETA=0:03:40\n",
      "\u001b[32m[03/15 17:35:56 d2.evaluation.evaluator]: \u001b[0mInference done 783/6397. Dataloading: 0.0082 s/iter. Inference: 0.0305 s/iter. Eval: 0.0003 s/iter. Total: 0.0390 s/iter. ETA=0:03:38\n",
      "\u001b[32m[03/15 17:36:01 d2.evaluation.evaluator]: \u001b[0mInference done 911/6397. Dataloading: 0.0081 s/iter. Inference: 0.0306 s/iter. Eval: 0.0003 s/iter. Total: 0.0390 s/iter. ETA=0:03:34\n",
      "\u001b[32m[03/15 17:36:06 d2.evaluation.evaluator]: \u001b[0mInference done 1041/6397. Dataloading: 0.0081 s/iter. Inference: 0.0305 s/iter. Eval: 0.0003 s/iter. Total: 0.0390 s/iter. ETA=0:03:28\n",
      "\u001b[32m[03/15 17:36:11 d2.evaluation.evaluator]: \u001b[0mInference done 1171/6397. Dataloading: 0.0081 s/iter. Inference: 0.0305 s/iter. Eval: 0.0003 s/iter. Total: 0.0389 s/iter. ETA=0:03:23\n",
      "\u001b[32m[03/15 17:36:16 d2.evaluation.evaluator]: \u001b[0mInference done 1288/6397. Dataloading: 0.0084 s/iter. Inference: 0.0305 s/iter. Eval: 0.0003 s/iter. Total: 0.0393 s/iter. ETA=0:03:20\n",
      "\u001b[32m[03/15 17:36:21 d2.evaluation.evaluator]: \u001b[0mInference done 1418/6397. Dataloading: 0.0084 s/iter. Inference: 0.0305 s/iter. Eval: 0.0003 s/iter. Total: 0.0392 s/iter. ETA=0:03:15\n",
      "\u001b[32m[03/15 17:36:26 d2.evaluation.evaluator]: \u001b[0mInference done 1548/6397. Dataloading: 0.0084 s/iter. Inference: 0.0305 s/iter. Eval: 0.0003 s/iter. Total: 0.0392 s/iter. ETA=0:03:09\n",
      "\u001b[32m[03/15 17:36:31 d2.evaluation.evaluator]: \u001b[0mInference done 1679/6397. Dataloading: 0.0083 s/iter. Inference: 0.0305 s/iter. Eval: 0.0003 s/iter. Total: 0.0391 s/iter. ETA=0:03:04\n",
      "\u001b[32m[03/15 17:36:36 d2.evaluation.evaluator]: \u001b[0mInference done 1800/6397. Dataloading: 0.0084 s/iter. Inference: 0.0305 s/iter. Eval: 0.0003 s/iter. Total: 0.0392 s/iter. ETA=0:03:00\n",
      "\u001b[32m[03/15 17:36:41 d2.evaluation.evaluator]: \u001b[0mInference done 1921/6397. Dataloading: 0.0084 s/iter. Inference: 0.0306 s/iter. Eval: 0.0003 s/iter. Total: 0.0394 s/iter. ETA=0:02:56\n",
      "\u001b[32m[03/15 17:36:46 d2.evaluation.evaluator]: \u001b[0mInference done 2043/6397. Dataloading: 0.0085 s/iter. Inference: 0.0307 s/iter. Eval: 0.0003 s/iter. Total: 0.0395 s/iter. ETA=0:02:51\n",
      "\u001b[32m[03/15 17:36:51 d2.evaluation.evaluator]: \u001b[0mInference done 2169/6397. Dataloading: 0.0085 s/iter. Inference: 0.0307 s/iter. Eval: 0.0003 s/iter. Total: 0.0395 s/iter. ETA=0:02:47\n",
      "\u001b[32m[03/15 17:36:57 d2.evaluation.evaluator]: \u001b[0mInference done 2300/6397. Dataloading: 0.0085 s/iter. Inference: 0.0307 s/iter. Eval: 0.0003 s/iter. Total: 0.0394 s/iter. ETA=0:02:41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/15 17:37:02 d2.evaluation.evaluator]: \u001b[0mInference done 2428/6397. Dataloading: 0.0084 s/iter. Inference: 0.0307 s/iter. Eval: 0.0003 s/iter. Total: 0.0394 s/iter. ETA=0:02:36\n",
      "\u001b[32m[03/15 17:37:07 d2.evaluation.evaluator]: \u001b[0mInference done 2558/6397. Dataloading: 0.0084 s/iter. Inference: 0.0306 s/iter. Eval: 0.0003 s/iter. Total: 0.0394 s/iter. ETA=0:02:31\n",
      "\u001b[32m[03/15 17:37:12 d2.evaluation.evaluator]: \u001b[0mInference done 2687/6397. Dataloading: 0.0084 s/iter. Inference: 0.0306 s/iter. Eval: 0.0003 s/iter. Total: 0.0394 s/iter. ETA=0:02:26\n",
      "\u001b[32m[03/15 17:37:17 d2.evaluation.evaluator]: \u001b[0mInference done 2814/6397. Dataloading: 0.0084 s/iter. Inference: 0.0307 s/iter. Eval: 0.0003 s/iter. Total: 0.0394 s/iter. ETA=0:02:21\n",
      "\u001b[32m[03/15 17:37:22 d2.evaluation.evaluator]: \u001b[0mInference done 2948/6397. Dataloading: 0.0084 s/iter. Inference: 0.0306 s/iter. Eval: 0.0003 s/iter. Total: 0.0393 s/iter. ETA=0:02:15\n",
      "\u001b[32m[03/15 17:37:27 d2.evaluation.evaluator]: \u001b[0mInference done 3069/6397. Dataloading: 0.0084 s/iter. Inference: 0.0306 s/iter. Eval: 0.0003 s/iter. Total: 0.0394 s/iter. ETA=0:02:11\n",
      "\u001b[32m[03/15 17:37:32 d2.evaluation.evaluator]: \u001b[0mInference done 3181/6397. Dataloading: 0.0086 s/iter. Inference: 0.0307 s/iter. Eval: 0.0003 s/iter. Total: 0.0396 s/iter. ETA=0:02:07\n",
      "\u001b[32m[03/15 17:37:37 d2.evaluation.evaluator]: \u001b[0mInference done 3303/6397. Dataloading: 0.0086 s/iter. Inference: 0.0307 s/iter. Eval: 0.0003 s/iter. Total: 0.0396 s/iter. ETA=0:02:02\n",
      "\u001b[32m[03/15 17:37:42 d2.evaluation.evaluator]: \u001b[0mInference done 3424/6397. Dataloading: 0.0086 s/iter. Inference: 0.0307 s/iter. Eval: 0.0003 s/iter. Total: 0.0397 s/iter. ETA=0:01:58\n",
      "\u001b[32m[03/15 17:37:47 d2.evaluation.evaluator]: \u001b[0mInference done 3549/6397. Dataloading: 0.0086 s/iter. Inference: 0.0308 s/iter. Eval: 0.0003 s/iter. Total: 0.0397 s/iter. ETA=0:01:53\n",
      "\u001b[32m[03/15 17:37:52 d2.evaluation.evaluator]: \u001b[0mInference done 3680/6397. Dataloading: 0.0086 s/iter. Inference: 0.0307 s/iter. Eval: 0.0003 s/iter. Total: 0.0397 s/iter. ETA=0:01:47\n",
      "\u001b[32m[03/15 17:37:57 d2.evaluation.evaluator]: \u001b[0mInference done 3802/6397. Dataloading: 0.0086 s/iter. Inference: 0.0308 s/iter. Eval: 0.0003 s/iter. Total: 0.0397 s/iter. ETA=0:01:43\n",
      "\u001b[32m[03/15 17:38:02 d2.evaluation.evaluator]: \u001b[0mInference done 3935/6397. Dataloading: 0.0086 s/iter. Inference: 0.0307 s/iter. Eval: 0.0003 s/iter. Total: 0.0396 s/iter. ETA=0:01:37\n",
      "\u001b[32m[03/15 17:38:07 d2.evaluation.evaluator]: \u001b[0mInference done 4068/6397. Dataloading: 0.0086 s/iter. Inference: 0.0307 s/iter. Eval: 0.0003 s/iter. Total: 0.0396 s/iter. ETA=0:01:32\n",
      "\u001b[32m[03/15 17:38:12 d2.evaluation.evaluator]: \u001b[0mInference done 4193/6397. Dataloading: 0.0086 s/iter. Inference: 0.0307 s/iter. Eval: 0.0003 s/iter. Total: 0.0396 s/iter. ETA=0:01:27\n",
      "\u001b[32m[03/15 17:38:17 d2.evaluation.evaluator]: \u001b[0mInference done 4315/6397. Dataloading: 0.0086 s/iter. Inference: 0.0307 s/iter. Eval: 0.0003 s/iter. Total: 0.0396 s/iter. ETA=0:01:22\n",
      "\u001b[32m[03/15 17:38:22 d2.evaluation.evaluator]: \u001b[0mInference done 4446/6397. Dataloading: 0.0086 s/iter. Inference: 0.0307 s/iter. Eval: 0.0003 s/iter. Total: 0.0396 s/iter. ETA=0:01:17\n",
      "\u001b[32m[03/15 17:38:27 d2.evaluation.evaluator]: \u001b[0mInference done 4578/6397. Dataloading: 0.0086 s/iter. Inference: 0.0307 s/iter. Eval: 0.0003 s/iter. Total: 0.0396 s/iter. ETA=0:01:11\n",
      "\u001b[32m[03/15 17:38:32 d2.evaluation.evaluator]: \u001b[0mInference done 4710/6397. Dataloading: 0.0085 s/iter. Inference: 0.0307 s/iter. Eval: 0.0003 s/iter. Total: 0.0395 s/iter. ETA=0:01:06\n",
      "\u001b[32m[03/15 17:38:37 d2.evaluation.evaluator]: \u001b[0mInference done 4840/6397. Dataloading: 0.0085 s/iter. Inference: 0.0307 s/iter. Eval: 0.0003 s/iter. Total: 0.0395 s/iter. ETA=0:01:01\n",
      "\u001b[32m[03/15 17:38:42 d2.evaluation.evaluator]: \u001b[0mInference done 4971/6397. Dataloading: 0.0085 s/iter. Inference: 0.0306 s/iter. Eval: 0.0003 s/iter. Total: 0.0395 s/iter. ETA=0:00:56\n",
      "\u001b[32m[03/15 17:38:47 d2.evaluation.evaluator]: \u001b[0mInference done 5101/6397. Dataloading: 0.0085 s/iter. Inference: 0.0306 s/iter. Eval: 0.0003 s/iter. Total: 0.0394 s/iter. ETA=0:00:51\n",
      "\u001b[32m[03/15 17:38:52 d2.evaluation.evaluator]: \u001b[0mInference done 5233/6397. Dataloading: 0.0085 s/iter. Inference: 0.0306 s/iter. Eval: 0.0003 s/iter. Total: 0.0394 s/iter. ETA=0:00:45\n",
      "\u001b[32m[03/15 17:38:57 d2.evaluation.evaluator]: \u001b[0mInference done 5364/6397. Dataloading: 0.0084 s/iter. Inference: 0.0306 s/iter. Eval: 0.0003 s/iter. Total: 0.0394 s/iter. ETA=0:00:40\n",
      "\u001b[32m[03/15 17:39:02 d2.evaluation.evaluator]: \u001b[0mInference done 5483/6397. Dataloading: 0.0085 s/iter. Inference: 0.0306 s/iter. Eval: 0.0003 s/iter. Total: 0.0394 s/iter. ETA=0:00:36\n",
      "\u001b[32m[03/15 17:39:07 d2.evaluation.evaluator]: \u001b[0mInference done 5614/6397. Dataloading: 0.0085 s/iter. Inference: 0.0306 s/iter. Eval: 0.0003 s/iter. Total: 0.0394 s/iter. ETA=0:00:30\n",
      "\u001b[32m[03/15 17:39:12 d2.evaluation.evaluator]: \u001b[0mInference done 5743/6397. Dataloading: 0.0085 s/iter. Inference: 0.0306 s/iter. Eval: 0.0003 s/iter. Total: 0.0394 s/iter. ETA=0:00:25\n",
      "\u001b[32m[03/15 17:39:17 d2.evaluation.evaluator]: \u001b[0mInference done 5865/6397. Dataloading: 0.0085 s/iter. Inference: 0.0306 s/iter. Eval: 0.0003 s/iter. Total: 0.0394 s/iter. ETA=0:00:20\n",
      "\u001b[32m[03/15 17:39:22 d2.evaluation.evaluator]: \u001b[0mInference done 5990/6397. Dataloading: 0.0085 s/iter. Inference: 0.0306 s/iter. Eval: 0.0003 s/iter. Total: 0.0395 s/iter. ETA=0:00:16\n",
      "\u001b[32m[03/15 17:39:27 d2.evaluation.evaluator]: \u001b[0mInference done 6112/6397. Dataloading: 0.0085 s/iter. Inference: 0.0307 s/iter. Eval: 0.0003 s/iter. Total: 0.0395 s/iter. ETA=0:00:11\n",
      "\u001b[32m[03/15 17:39:32 d2.evaluation.evaluator]: \u001b[0mInference done 6234/6397. Dataloading: 0.0085 s/iter. Inference: 0.0307 s/iter. Eval: 0.0003 s/iter. Total: 0.0395 s/iter. ETA=0:00:06\n",
      "\u001b[32m[03/15 17:39:37 d2.evaluation.evaluator]: \u001b[0mInference done 6357/6397. Dataloading: 0.0085 s/iter. Inference: 0.0307 s/iter. Eval: 0.0003 s/iter. Total: 0.0395 s/iter. ETA=0:00:01\n",
      "\u001b[32m[03/15 17:39:39 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:04:12.861353 (0.039559 s / iter per device, on 1 devices)\n",
      "\u001b[32m[03/15 17:39:39 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:03:16 (0.030696 s / iter per device, on 1 devices)\n",
      "\u001b[32m[03/15 17:39:42 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[03/15 17:39:42 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./exp_on_FasterRCNN/inference/coco_instances_results.json\n",
      "\u001b[32m[03/15 17:39:45 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=1.72s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[03/15 17:39:47 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[03/15 17:40:07 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 20.13 seconds.\n",
      "\u001b[32m[03/15 17:40:07 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[03/15 17:40:10 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 2.84 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.690\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.883\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.817\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.595\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.736\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.840\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.653\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.749\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.749\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.668\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.786\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.873\n",
      "\u001b[32m[03/15 17:40:10 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 69.004 | 88.278 | 81.731 | 59.511 | 73.584 | 83.969 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/15 17:40:10 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category                   | AP     | category                     | AP     | category                     | AP     |\n",
      "|:---------------------------|:-------|:-----------------------------|:-------|:-----------------------------|:-------|\n",
      "| 000_aveda_shampoo          | 71.083 | 001_binder_clips_median      | 77.910 | 002_binder_clips_small       | 70.928 |\n",
      "| 003_bombik_bucket          | 83.108 | 004_bonne_maman_blueberry    | 66.292 | 005_bonne_maman_raspberry    | 45.002 |\n",
      "| 006_bonne_maman_strawberry | 38.503 | 007_costa_caramel            | 68.498 | 008_essential_oil_bergamot   | 64.014 |\n",
      "| 009_garlic_toast_spread    | 46.432 | 010_handcream_avocado        | 55.716 | 011_hb_calcium               | 80.809 |\n",
      "| 012_hb_grapeseed           | 79.404 | 013_hb_marine_collagen       | 63.965 | 014_hellmanns_mayonnaise     | 74.972 |\n",
      "| 015_illy_blend             | 71.539 | 016_japanese_finger_cookies  | 82.585 | 017_john_west_canned_tuna    | 80.154 |\n",
      "| 018_kerastase_shampoo      | 71.388 | 019_kiehls_facial_cream      | 69.949 | 020_kiihne_balsamic          | 69.366 |\n",
      "| 021_kiihne_honey_mustard   | 73.148 | 022_lindor_matcha            | 78.897 | 023_lindor_salted_caramel    | 80.103 |\n",
      "| 024_lush_mask              | 83.337 | 025_pasta_sauce_black_pepper | 46.294 | 026_pasta_sauce_tomato       | 42.207 |\n",
      "| 027_pepsi                  | 80.825 | 028_portable_yogurt_machine  | 68.448 | 029_selfile_stick            | 71.097 |\n",
      "| 030_sour_lemon_drops       | 75.851 | 031_sticky_notes             | 69.960 | 032_stridex_green            | 72.346 |\n",
      "| 033_thermos_flask_cream    | 75.814 | 034_thermos_flask_muji       | 74.254 | 035_thermos_flask_sliver     | 76.377 |\n",
      "| 036_tragata_olive_oil      | 66.213 | 037_tulip_luncheon_meat      | 77.522 | 038_unicharm_cotton_pad      | 74.728 |\n",
      "| 039_vinda_tissue           | 75.117 | 040_wrigley_doublemint_gum   | 68.333 | 041_baseball_cap_black       | 77.549 |\n",
      "| 042_baseball_cap_pink      | 79.520 | 043_bfe_facial_mask          | 75.096 | 044_corgi_doll               | 68.553 |\n",
      "| 045_dinosaur_doll          | 78.395 | 046_geo_mocha                | 72.077 | 047_geo_roast_charcoal       | 69.789 |\n",
      "| 048_instant_noodle_black   | 71.555 | 049_instant_noodle_red       | 76.940 | 050_nabati_cheese_wafer      | 81.516 |\n",
      "| 051_truffettes             | 73.912 | 052_acnes_cream              | 63.592 | 053_aveda_conditioner        | 68.673 |\n",
      "| 054_banana_milk_drink      | 76.908 | 055_candle_beast             | 83.421 | 056_china_persimmon          | 84.392 |\n",
      "| 057_danisa_butter_cookies  | 70.407 | 058_effaclar_duo             | 49.301 | 059_evelom_cleanser          | 61.227 |\n",
      "| 060_glasses_box_blone      | 72.733 | 061_handcream_iris           | 46.776 | 062_handcream_lavender       | 40.747 |\n",
      "| 063_handcream_rosewater    | 64.521 | 064_handcream_summer_hill    | 42.084 | 065_hr_serum                 | 68.334 |\n",
      "| 066_japanese_chocolate     | 78.801 | 067_kerastase_hair_treatment | 60.366 | 068_kiehls_serum             | 63.363 |\n",
      "| 069_korean_beef_marinade   | 71.154 | 070_korean_doenjang          | 81.140 | 071_korean_gochujang         | 80.588 |\n",
      "| 072_korean_ssamjang        | 80.111 | 073_loccitane_soap           | 70.614 | 074_marvis_toothpaste_purple | 54.619 |\n",
      "| 075_mouse_thinkpad         | 67.436 | 076_oatly_chocolate          | 68.812 | 077_oatly_original           | 67.372 |\n",
      "| 078_ousa_grated_cheese     | 71.040 | 079_polaroid_film            | 71.525 | 080_skinceuticals_be         | 75.239 |\n",
      "| 081_skinceuticals_cf       | 52.833 | 082_skinceuticals_phyto      | 65.912 | 083_stapler_black            | 67.257 |\n",
      "| 084_stapler_blue           | 70.485 | 085_sunscreen_blue           | 52.713 | 086_tempo_pocket_tissue      | 61.141 |\n",
      "| 087_thermos_flask_purple   | 76.664 | 088_uha_matcha               | 62.407 | 089_urban_decay_spray        | 70.881 |\n",
      "| 090_vitaboost_multivitamin | 67.663 | 091_watercolor_penbox        | 61.374 | 092_youthlt_bilberry_complex | 66.789 |\n",
      "| 093_daiso_mod_remover      | 60.020 | 094_kaneyo_kitchen_bleach    | 65.592 | 095_lays_chip_bag_blue       | 69.564 |\n",
      "| 096_lays_chip_bag_green    | 66.082 | 097_lays_chip_tube_auburn    | 77.870 | 098_lays_chip_tube_green     | 73.611 |\n",
      "| 099_mug_blue               | 68.814 |                              |        |                              |        |\n",
      "\u001b[32m[03/15 17:40:12 d2.engine.defaults]: \u001b[0mEvaluation results for coco_realDB_val in csv format:\n",
      "\u001b[32m[03/15 17:40:12 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/15 17:40:12 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/15 17:40:12 d2.evaluation.testing]: \u001b[0mcopypaste: 69.0036,88.2780,81.7313,59.5110,73.5843,83.9686\n",
      "\u001b[32m[03/15 17:40:12 d2.utils.events]: \u001b[0m eta: 0:06:32  iter: 1499  total_loss: 0.7452  loss_cls: 0.294  loss_box_reg: 0.2855  loss_rpn_cls: 0.0375  loss_rpn_loc: 0.1249  time: 0.7898  data_time: 0.3618  lr: 0.002  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:40:29 d2.utils.events]: \u001b[0m eta: 0:06:16  iter: 1519  total_loss: 0.7306  loss_cls: 0.283  loss_box_reg: 0.2806  loss_rpn_cls: 0.03305  loss_rpn_loc: 0.1304  time: 0.7903  data_time: 0.3865  lr: 0.002  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:40:45 d2.utils.events]: \u001b[0m eta: 0:06:01  iter: 1539  total_loss: 0.7805  loss_cls: 0.3041  loss_box_reg: 0.2789  loss_rpn_cls: 0.03323  loss_rpn_loc: 0.1279  time: 0.7905  data_time: 0.3642  lr: 0.002  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:41:00 d2.utils.events]: \u001b[0m eta: 0:05:45  iter: 1559  total_loss: 0.7307  loss_cls: 0.2905  loss_box_reg: 0.2791  loss_rpn_cls: 0.03321  loss_rpn_loc: 0.1244  time: 0.7904  data_time: 0.3373  lr: 0.002  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:41:16 d2.utils.events]: \u001b[0m eta: 0:05:29  iter: 1579  total_loss: 0.7281  loss_cls: 0.2818  loss_box_reg: 0.2763  loss_rpn_cls: 0.03521  loss_rpn_loc: 0.1268  time: 0.7903  data_time: 0.3337  lr: 0.002  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:41:32 d2.utils.events]: \u001b[0m eta: 0:05:14  iter: 1599  total_loss: 0.7177  loss_cls: 0.295  loss_box_reg: 0.2679  loss_rpn_cls: 0.03074  loss_rpn_loc: 0.1223  time: 0.7903  data_time: 0.3434  lr: 0.002  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:41:48 d2.utils.events]: \u001b[0m eta: 0:04:58  iter: 1619  total_loss: 0.6963  loss_cls: 0.2712  loss_box_reg: 0.2688  loss_rpn_cls: 0.03135  loss_rpn_loc: 0.1191  time: 0.7902  data_time: 0.3362  lr: 0.002  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:42:04 d2.utils.events]: \u001b[0m eta: 0:04:42  iter: 1639  total_loss: 0.7327  loss_cls: 0.2816  loss_box_reg: 0.2727  loss_rpn_cls: 0.03665  loss_rpn_loc: 0.1335  time: 0.7904  data_time: 0.3653  lr: 0.002  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:42:20 d2.utils.events]: \u001b[0m eta: 0:04:26  iter: 1659  total_loss: 0.69  loss_cls: 0.2702  loss_box_reg: 0.2656  loss_rpn_cls: 0.02894  loss_rpn_loc: 0.1219  time: 0.7904  data_time: 0.3416  lr: 0.002  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:42:35 d2.utils.events]: \u001b[0m eta: 0:04:11  iter: 1679  total_loss: 0.7355  loss_cls: 0.2796  loss_box_reg: 0.2751  loss_rpn_cls: 0.03556  loss_rpn_loc: 0.1281  time: 0.7904  data_time: 0.3421  lr: 0.002  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:42:52 d2.utils.events]: \u001b[0m eta: 0:03:55  iter: 1699  total_loss: 0.7034  loss_cls: 0.2636  loss_box_reg: 0.273  loss_rpn_cls: 0.03057  loss_rpn_loc: 0.1238  time: 0.7907  data_time: 0.3671  lr: 0.002  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:43:08 d2.utils.events]: \u001b[0m eta: 0:03:40  iter: 1719  total_loss: 0.7234  loss_cls: 0.2864  loss_box_reg: 0.2717  loss_rpn_cls: 0.03009  loss_rpn_loc: 0.133  time: 0.7908  data_time: 0.3543  lr: 0.002  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:43:24 d2.utils.events]: \u001b[0m eta: 0:03:24  iter: 1739  total_loss: 0.685  loss_cls: 0.2693  loss_box_reg: 0.2616  loss_rpn_cls: 0.03434  loss_rpn_loc: 0.1281  time: 0.7910  data_time: 0.3600  lr: 0.002  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:43:40 d2.utils.events]: \u001b[0m eta: 0:03:08  iter: 1759  total_loss: 0.7  loss_cls: 0.2714  loss_box_reg: 0.2683  loss_rpn_cls: 0.03483  loss_rpn_loc: 0.131  time: 0.7911  data_time: 0.3527  lr: 0.002  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:43:57 d2.utils.events]: \u001b[0m eta: 0:02:52  iter: 1779  total_loss: 0.6745  loss_cls: 0.2691  loss_box_reg: 0.2666  loss_rpn_cls: 0.02632  loss_rpn_loc: 0.1172  time: 0.7915  data_time: 0.3804  lr: 0.002  max_mem: 7021M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/15 17:44:12 d2.utils.events]: \u001b[0m eta: 0:02:37  iter: 1799  total_loss: 0.664  loss_cls: 0.2586  loss_box_reg: 0.2597  loss_rpn_cls: 0.03008  loss_rpn_loc: 0.1181  time: 0.7913  data_time: 0.3284  lr: 0.002  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:44:28 d2.utils.events]: \u001b[0m eta: 0:02:21  iter: 1819  total_loss: 0.6943  loss_cls: 0.2657  loss_box_reg: 0.2679  loss_rpn_cls: 0.03277  loss_rpn_loc: 0.1239  time: 0.7913  data_time: 0.3451  lr: 0.002  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:44:44 d2.utils.events]: \u001b[0m eta: 0:02:06  iter: 1839  total_loss: 0.7003  loss_cls: 0.2747  loss_box_reg: 0.2687  loss_rpn_cls: 0.03604  loss_rpn_loc: 0.1249  time: 0.7914  data_time: 0.3525  lr: 0.002  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:45:00 d2.utils.events]: \u001b[0m eta: 0:01:50  iter: 1859  total_loss: 0.6919  loss_cls: 0.2589  loss_box_reg: 0.2645  loss_rpn_cls: 0.03023  loss_rpn_loc: 0.1132  time: 0.7914  data_time: 0.3416  lr: 0.002  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:45:16 d2.utils.events]: \u001b[0m eta: 0:01:34  iter: 1879  total_loss: 0.6803  loss_cls: 0.2669  loss_box_reg: 0.27  loss_rpn_cls: 0.03236  loss_rpn_loc: 0.1229  time: 0.7916  data_time: 0.3624  lr: 0.002  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:45:32 d2.utils.events]: \u001b[0m eta: 0:01:18  iter: 1899  total_loss: 0.6725  loss_cls: 0.2572  loss_box_reg: 0.2608  loss_rpn_cls: 0.03103  loss_rpn_loc: 0.1188  time: 0.7917  data_time: 0.3541  lr: 0.002  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:45:48 d2.utils.events]: \u001b[0m eta: 0:01:03  iter: 1919  total_loss: 0.6578  loss_cls: 0.2615  loss_box_reg: 0.2614  loss_rpn_cls: 0.02876  loss_rpn_loc: 0.1159  time: 0.7916  data_time: 0.3392  lr: 0.002  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:46:04 d2.utils.events]: \u001b[0m eta: 0:00:47  iter: 1939  total_loss: 0.7069  loss_cls: 0.2721  loss_box_reg: 0.2687  loss_rpn_cls: 0.03311  loss_rpn_loc: 0.1265  time: 0.7917  data_time: 0.3468  lr: 0.002  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:46:20 d2.utils.events]: \u001b[0m eta: 0:00:31  iter: 1959  total_loss: 0.7034  loss_cls: 0.2635  loss_box_reg: 0.2616  loss_rpn_cls: 0.03161  loss_rpn_loc: 0.1304  time: 0.7917  data_time: 0.3479  lr: 0.002  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:46:35 d2.utils.events]: \u001b[0m eta: 0:00:15  iter: 1979  total_loss: 0.7016  loss_cls: 0.2722  loss_box_reg: 0.2701  loss_rpn_cls: 0.0331  loss_rpn_loc: 0.1162  time: 0.7918  data_time: 0.3469  lr: 0.002  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:46:52 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 1999  total_loss: 0.6934  loss_cls: 0.2632  loss_box_reg: 0.2548  loss_rpn_cls: 0.03334  loss_rpn_loc: 0.1212  time: 0.7918  data_time: 0.3456  lr: 0.002  max_mem: 7021M\n",
      "\u001b[32m[03/15 17:46:52 d2.engine.hooks]: \u001b[0mOverall training speed: 1998 iterations in 0:26:22 (0.7918 s / it)\n",
      "\u001b[32m[03/15 17:46:52 d2.engine.hooks]: \u001b[0mTotal training time: 0:41:14 (0:14:52 on hooks)\n",
      "\u001b[32m[03/15 17:46:53 d2.data.datasets.coco]: \u001b[0mLoaded 6397 images in COCO format from /home/SQQ/svid/NeRFDetExps/Data/annotations/instances_val.json\n",
      "\u001b[32m[03/15 17:46:54 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(0, 0), max_size=1024, sample_style='choice')]\n",
      "\u001b[32m[03/15 17:46:54 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n",
      "\u001b[32m[03/15 17:46:54 d2.data.common]: \u001b[0mSerializing 6397 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/15 17:46:54 d2.data.common]: \u001b[0mSerialized dataset takes 26.74 MiB\n",
      "\u001b[32m[03/15 17:46:56 d2.evaluation.evaluator]: \u001b[0mStart inference on 6397 batches\n",
      "\u001b[32m[03/15 17:46:56 d2.evaluation.evaluator]: \u001b[0mInference done 11/6397. Dataloading: 0.0077 s/iter. Inference: 0.0313 s/iter. Eval: 0.0003 s/iter. Total: 0.0393 s/iter. ETA=0:04:10\n",
      "\u001b[32m[03/15 17:47:01 d2.evaluation.evaluator]: \u001b[0mInference done 137/6397. Dataloading: 0.0087 s/iter. Inference: 0.0308 s/iter. Eval: 0.0003 s/iter. Total: 0.0399 s/iter. ETA=0:04:09\n",
      "\u001b[32m[03/15 17:47:06 d2.evaluation.evaluator]: \u001b[0mInference done 274/6397. Dataloading: 0.0082 s/iter. Inference: 0.0298 s/iter. Eval: 0.0002 s/iter. Total: 0.0382 s/iter. ETA=0:03:54\n",
      "\u001b[32m[03/15 17:47:11 d2.evaluation.evaluator]: \u001b[0mInference done 410/6397. Dataloading: 0.0080 s/iter. Inference: 0.0295 s/iter. Eval: 0.0002 s/iter. Total: 0.0378 s/iter. ETA=0:03:46\n",
      "\u001b[32m[03/15 17:47:16 d2.evaluation.evaluator]: \u001b[0mInference done 523/6397. Dataloading: 0.0089 s/iter. Inference: 0.0300 s/iter. Eval: 0.0002 s/iter. Total: 0.0392 s/iter. ETA=0:03:50\n",
      "\u001b[32m[03/15 17:47:21 d2.evaluation.evaluator]: \u001b[0mInference done 651/6397. Dataloading: 0.0088 s/iter. Inference: 0.0301 s/iter. Eval: 0.0002 s/iter. Total: 0.0392 s/iter. ETA=0:03:45\n",
      "\u001b[32m[03/15 17:47:26 d2.evaluation.evaluator]: \u001b[0mInference done 776/6397. Dataloading: 0.0088 s/iter. Inference: 0.0303 s/iter. Eval: 0.0002 s/iter. Total: 0.0393 s/iter. ETA=0:03:41\n",
      "\u001b[32m[03/15 17:47:31 d2.evaluation.evaluator]: \u001b[0mInference done 906/6397. Dataloading: 0.0087 s/iter. Inference: 0.0302 s/iter. Eval: 0.0002 s/iter. Total: 0.0393 s/iter. ETA=0:03:35\n",
      "\u001b[32m[03/15 17:47:36 d2.evaluation.evaluator]: \u001b[0mInference done 1034/6397. Dataloading: 0.0086 s/iter. Inference: 0.0303 s/iter. Eval: 0.0002 s/iter. Total: 0.0392 s/iter. ETA=0:03:30\n",
      "\u001b[32m[03/15 17:47:41 d2.evaluation.evaluator]: \u001b[0mInference done 1164/6397. Dataloading: 0.0086 s/iter. Inference: 0.0303 s/iter. Eval: 0.0002 s/iter. Total: 0.0392 s/iter. ETA=0:03:24\n",
      "\u001b[32m[03/15 17:47:46 d2.evaluation.evaluator]: \u001b[0mInference done 1290/6397. Dataloading: 0.0086 s/iter. Inference: 0.0303 s/iter. Eval: 0.0002 s/iter. Total: 0.0392 s/iter. ETA=0:03:20\n",
      "\u001b[32m[03/15 17:47:51 d2.evaluation.evaluator]: \u001b[0mInference done 1412/6397. Dataloading: 0.0086 s/iter. Inference: 0.0304 s/iter. Eval: 0.0003 s/iter. Total: 0.0394 s/iter. ETA=0:03:16\n",
      "\u001b[32m[03/15 17:47:56 d2.evaluation.evaluator]: \u001b[0mInference done 1534/6397. Dataloading: 0.0087 s/iter. Inference: 0.0305 s/iter. Eval: 0.0003 s/iter. Total: 0.0395 s/iter. ETA=0:03:12\n",
      "\u001b[32m[03/15 17:48:01 d2.evaluation.evaluator]: \u001b[0mInference done 1660/6397. Dataloading: 0.0086 s/iter. Inference: 0.0306 s/iter. Eval: 0.0003 s/iter. Total: 0.0396 s/iter. ETA=0:03:07\n",
      "\u001b[32m[03/15 17:48:06 d2.evaluation.evaluator]: \u001b[0mInference done 1788/6397. Dataloading: 0.0086 s/iter. Inference: 0.0306 s/iter. Eval: 0.0003 s/iter. Total: 0.0395 s/iter. ETA=0:03:02\n",
      "\u001b[32m[03/15 17:48:11 d2.evaluation.evaluator]: \u001b[0mInference done 1913/6397. Dataloading: 0.0086 s/iter. Inference: 0.0306 s/iter. Eval: 0.0003 s/iter. Total: 0.0396 s/iter. ETA=0:02:57\n",
      "\u001b[32m[03/15 17:48:16 d2.evaluation.evaluator]: \u001b[0mInference done 2044/6397. Dataloading: 0.0086 s/iter. Inference: 0.0306 s/iter. Eval: 0.0003 s/iter. Total: 0.0395 s/iter. ETA=0:02:51\n",
      "\u001b[32m[03/15 17:48:21 d2.evaluation.evaluator]: \u001b[0mInference done 2173/6397. Dataloading: 0.0086 s/iter. Inference: 0.0306 s/iter. Eval: 0.0003 s/iter. Total: 0.0395 s/iter. ETA=0:02:46\n",
      "\u001b[32m[03/15 17:48:26 d2.evaluation.evaluator]: \u001b[0mInference done 2303/6397. Dataloading: 0.0085 s/iter. Inference: 0.0305 s/iter. Eval: 0.0003 s/iter. Total: 0.0394 s/iter. ETA=0:02:41\n",
      "\u001b[32m[03/15 17:48:31 d2.evaluation.evaluator]: \u001b[0mInference done 2435/6397. Dataloading: 0.0085 s/iter. Inference: 0.0305 s/iter. Eval: 0.0003 s/iter. Total: 0.0393 s/iter. ETA=0:02:35\n",
      "\u001b[32m[03/15 17:48:36 d2.evaluation.evaluator]: \u001b[0mInference done 2557/6397. Dataloading: 0.0086 s/iter. Inference: 0.0305 s/iter. Eval: 0.0003 s/iter. Total: 0.0394 s/iter. ETA=0:02:31\n",
      "\u001b[32m[03/15 17:48:41 d2.evaluation.evaluator]: \u001b[0mInference done 2688/6397. Dataloading: 0.0086 s/iter. Inference: 0.0305 s/iter. Eval: 0.0003 s/iter. Total: 0.0394 s/iter. ETA=0:02:26\n",
      "\u001b[32m[03/15 17:48:46 d2.evaluation.evaluator]: \u001b[0mInference done 2819/6397. Dataloading: 0.0086 s/iter. Inference: 0.0304 s/iter. Eval: 0.0003 s/iter. Total: 0.0393 s/iter. ETA=0:02:20\n",
      "\u001b[32m[03/15 17:48:51 d2.evaluation.evaluator]: \u001b[0mInference done 2941/6397. Dataloading: 0.0086 s/iter. Inference: 0.0305 s/iter. Eval: 0.0003 s/iter. Total: 0.0394 s/iter. ETA=0:02:16\n",
      "\u001b[32m[03/15 17:48:56 d2.evaluation.evaluator]: \u001b[0mInference done 3063/6397. Dataloading: 0.0086 s/iter. Inference: 0.0305 s/iter. Eval: 0.0003 s/iter. Total: 0.0395 s/iter. ETA=0:02:11\n",
      "\u001b[32m[03/15 17:49:01 d2.evaluation.evaluator]: \u001b[0mInference done 3186/6397. Dataloading: 0.0086 s/iter. Inference: 0.0306 s/iter. Eval: 0.0003 s/iter. Total: 0.0395 s/iter. ETA=0:02:06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/15 17:49:07 d2.evaluation.evaluator]: \u001b[0mInference done 3308/6397. Dataloading: 0.0087 s/iter. Inference: 0.0306 s/iter. Eval: 0.0003 s/iter. Total: 0.0396 s/iter. ETA=0:02:02\n",
      "\u001b[32m[03/15 17:49:12 d2.evaluation.evaluator]: \u001b[0mInference done 3429/6397. Dataloading: 0.0087 s/iter. Inference: 0.0306 s/iter. Eval: 0.0003 s/iter. Total: 0.0396 s/iter. ETA=0:01:57\n",
      "\u001b[32m[03/15 17:49:17 d2.evaluation.evaluator]: \u001b[0mInference done 3550/6397. Dataloading: 0.0087 s/iter. Inference: 0.0307 s/iter. Eval: 0.0003 s/iter. Total: 0.0397 s/iter. ETA=0:01:53\n",
      "\u001b[32m[03/15 17:49:22 d2.evaluation.evaluator]: \u001b[0mInference done 3672/6397. Dataloading: 0.0087 s/iter. Inference: 0.0307 s/iter. Eval: 0.0003 s/iter. Total: 0.0398 s/iter. ETA=0:01:48\n",
      "\u001b[32m[03/15 17:49:27 d2.evaluation.evaluator]: \u001b[0mInference done 3793/6397. Dataloading: 0.0088 s/iter. Inference: 0.0307 s/iter. Eval: 0.0003 s/iter. Total: 0.0398 s/iter. ETA=0:01:43\n",
      "\u001b[32m[03/15 17:49:32 d2.evaluation.evaluator]: \u001b[0mInference done 3913/6397. Dataloading: 0.0088 s/iter. Inference: 0.0308 s/iter. Eval: 0.0003 s/iter. Total: 0.0399 s/iter. ETA=0:01:39\n",
      "\u001b[32m[03/15 17:49:37 d2.evaluation.evaluator]: \u001b[0mInference done 4033/6397. Dataloading: 0.0088 s/iter. Inference: 0.0308 s/iter. Eval: 0.0003 s/iter. Total: 0.0399 s/iter. ETA=0:01:34\n",
      "\u001b[32m[03/15 17:49:42 d2.evaluation.evaluator]: \u001b[0mInference done 4154/6397. Dataloading: 0.0088 s/iter. Inference: 0.0308 s/iter. Eval: 0.0003 s/iter. Total: 0.0400 s/iter. ETA=0:01:29\n",
      "\u001b[32m[03/15 17:49:47 d2.evaluation.evaluator]: \u001b[0mInference done 4282/6397. Dataloading: 0.0088 s/iter. Inference: 0.0308 s/iter. Eval: 0.0003 s/iter. Total: 0.0399 s/iter. ETA=0:01:24\n",
      "\u001b[32m[03/15 17:49:52 d2.evaluation.evaluator]: \u001b[0mInference done 4408/6397. Dataloading: 0.0088 s/iter. Inference: 0.0308 s/iter. Eval: 0.0003 s/iter. Total: 0.0399 s/iter. ETA=0:01:19\n",
      "\u001b[32m[03/15 17:49:57 d2.evaluation.evaluator]: \u001b[0mInference done 4527/6397. Dataloading: 0.0088 s/iter. Inference: 0.0308 s/iter. Eval: 0.0003 s/iter. Total: 0.0400 s/iter. ETA=0:01:14\n",
      "\u001b[32m[03/15 17:50:02 d2.evaluation.evaluator]: \u001b[0mInference done 4651/6397. Dataloading: 0.0088 s/iter. Inference: 0.0309 s/iter. Eval: 0.0003 s/iter. Total: 0.0400 s/iter. ETA=0:01:09\n",
      "\u001b[32m[03/15 17:50:07 d2.evaluation.evaluator]: \u001b[0mInference done 4778/6397. Dataloading: 0.0088 s/iter. Inference: 0.0309 s/iter. Eval: 0.0003 s/iter. Total: 0.0400 s/iter. ETA=0:01:04\n",
      "\u001b[32m[03/15 17:50:12 d2.evaluation.evaluator]: \u001b[0mInference done 4897/6397. Dataloading: 0.0088 s/iter. Inference: 0.0309 s/iter. Eval: 0.0003 s/iter. Total: 0.0400 s/iter. ETA=0:01:00\n",
      "\u001b[32m[03/15 17:50:17 d2.evaluation.evaluator]: \u001b[0mInference done 5006/6397. Dataloading: 0.0089 s/iter. Inference: 0.0309 s/iter. Eval: 0.0003 s/iter. Total: 0.0402 s/iter. ETA=0:00:55\n",
      "\u001b[32m[03/15 17:50:22 d2.evaluation.evaluator]: \u001b[0mInference done 5125/6397. Dataloading: 0.0090 s/iter. Inference: 0.0309 s/iter. Eval: 0.0003 s/iter. Total: 0.0402 s/iter. ETA=0:00:51\n",
      "\u001b[32m[03/15 17:50:27 d2.evaluation.evaluator]: \u001b[0mInference done 5245/6397. Dataloading: 0.0090 s/iter. Inference: 0.0309 s/iter. Eval: 0.0003 s/iter. Total: 0.0403 s/iter. ETA=0:00:46\n",
      "\u001b[32m[03/15 17:50:32 d2.evaluation.evaluator]: \u001b[0mInference done 5366/6397. Dataloading: 0.0090 s/iter. Inference: 0.0310 s/iter. Eval: 0.0003 s/iter. Total: 0.0403 s/iter. ETA=0:00:41\n",
      "\u001b[32m[03/15 17:50:37 d2.evaluation.evaluator]: \u001b[0mInference done 5489/6397. Dataloading: 0.0090 s/iter. Inference: 0.0310 s/iter. Eval: 0.0003 s/iter. Total: 0.0403 s/iter. ETA=0:00:36\n",
      "\u001b[32m[03/15 17:50:42 d2.evaluation.evaluator]: \u001b[0mInference done 5610/6397. Dataloading: 0.0090 s/iter. Inference: 0.0310 s/iter. Eval: 0.0003 s/iter. Total: 0.0403 s/iter. ETA=0:00:31\n",
      "\u001b[32m[03/15 17:50:47 d2.evaluation.evaluator]: \u001b[0mInference done 5731/6397. Dataloading: 0.0090 s/iter. Inference: 0.0310 s/iter. Eval: 0.0003 s/iter. Total: 0.0403 s/iter. ETA=0:00:26\n",
      "\u001b[32m[03/15 17:50:52 d2.evaluation.evaluator]: \u001b[0mInference done 5861/6397. Dataloading: 0.0090 s/iter. Inference: 0.0310 s/iter. Eval: 0.0003 s/iter. Total: 0.0403 s/iter. ETA=0:00:21\n",
      "\u001b[32m[03/15 17:50:57 d2.evaluation.evaluator]: \u001b[0mInference done 5991/6397. Dataloading: 0.0090 s/iter. Inference: 0.0310 s/iter. Eval: 0.0003 s/iter. Total: 0.0403 s/iter. ETA=0:00:16\n",
      "\u001b[32m[03/15 17:51:02 d2.evaluation.evaluator]: \u001b[0mInference done 6122/6397. Dataloading: 0.0089 s/iter. Inference: 0.0310 s/iter. Eval: 0.0003 s/iter. Total: 0.0402 s/iter. ETA=0:00:11\n",
      "\u001b[32m[03/15 17:51:07 d2.evaluation.evaluator]: \u001b[0mInference done 6253/6397. Dataloading: 0.0089 s/iter. Inference: 0.0309 s/iter. Eval: 0.0003 s/iter. Total: 0.0402 s/iter. ETA=0:00:05\n",
      "\u001b[32m[03/15 17:51:12 d2.evaluation.evaluator]: \u001b[0mInference done 6377/6397. Dataloading: 0.0089 s/iter. Inference: 0.0309 s/iter. Eval: 0.0003 s/iter. Total: 0.0402 s/iter. ETA=0:00:00\n",
      "\u001b[32m[03/15 17:51:13 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:04:16.902406 (0.040191 s / iter per device, on 1 devices)\n",
      "\u001b[32m[03/15 17:51:13 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:03:17 (0.030951 s / iter per device, on 1 devices)\n",
      "\u001b[32m[03/15 17:51:15 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[03/15 17:51:15 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./exp_on_FasterRCNN/inference/coco_instances_results.json\n",
      "\u001b[32m[03/15 17:51:18 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=1.50s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[03/15 17:51:19 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[03/15 17:51:37 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 17.99 seconds.\n",
      "\u001b[32m[03/15 17:51:37 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[03/15 17:51:40 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 2.44 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.703\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.896\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.834\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.610\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.747\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.849\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.660\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.755\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.755\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.671\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.792\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.879\n",
      "\u001b[32m[03/15 17:51:40 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 70.301 | 89.647 | 83.435 | 60.962 | 74.731 | 84.918 |\n",
      "\u001b[32m[03/15 17:51:40 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category                   | AP     | category                     | AP     | category                     | AP     |\n",
      "|:---------------------------|:-------|:-----------------------------|:-------|:-----------------------------|:-------|\n",
      "| 000_aveda_shampoo          | 71.965 | 001_binder_clips_median      | 81.539 | 002_binder_clips_small       | 73.419 |\n",
      "| 003_bombik_bucket          | 75.348 | 004_bonne_maman_blueberry    | 69.327 | 005_bonne_maman_raspberry    | 43.187 |\n",
      "| 006_bonne_maman_strawberry | 41.686 | 007_costa_caramel            | 69.779 | 008_essential_oil_bergamot   | 63.649 |\n",
      "| 009_garlic_toast_spread    | 45.880 | 010_handcream_avocado        | 55.048 | 011_hb_calcium               | 68.198 |\n",
      "| 012_hb_grapeseed           | 77.868 | 013_hb_marine_collagen       | 66.351 | 014_hellmanns_mayonnaise     | 76.846 |\n",
      "| 015_illy_blend             | 75.193 | 016_japanese_finger_cookies  | 85.766 | 017_john_west_canned_tuna    | 77.449 |\n",
      "| 018_kerastase_shampoo      | 71.354 | 019_kiehls_facial_cream      | 69.730 | 020_kiihne_balsamic          | 70.546 |\n",
      "| 021_kiihne_honey_mustard   | 76.445 | 022_lindor_matcha            | 80.028 | 023_lindor_salted_caramel    | 80.783 |\n",
      "| 024_lush_mask              | 85.295 | 025_pasta_sauce_black_pepper | 49.898 | 026_pasta_sauce_tomato       | 46.213 |\n",
      "| 027_pepsi                  | 83.240 | 028_portable_yogurt_machine  | 68.631 | 029_selfile_stick            | 72.612 |\n",
      "| 030_sour_lemon_drops       | 74.943 | 031_sticky_notes             | 73.217 | 032_stridex_green            | 71.157 |\n",
      "| 033_thermos_flask_cream    | 75.475 | 034_thermos_flask_muji       | 76.533 | 035_thermos_flask_sliver     | 73.100 |\n",
      "| 036_tragata_olive_oil      | 68.515 | 037_tulip_luncheon_meat      | 78.392 | 038_unicharm_cotton_pad      | 71.864 |\n",
      "| 039_vinda_tissue           | 70.352 | 040_wrigley_doublemint_gum   | 72.816 | 041_baseball_cap_black       | 75.029 |\n",
      "| 042_baseball_cap_pink      | 80.311 | 043_bfe_facial_mask          | 77.680 | 044_corgi_doll               | 68.977 |\n",
      "| 045_dinosaur_doll          | 76.879 | 046_geo_mocha                | 70.625 | 047_geo_roast_charcoal       | 67.610 |\n",
      "| 048_instant_noodle_black   | 71.853 | 049_instant_noodle_red       | 73.640 | 050_nabati_cheese_wafer      | 82.534 |\n",
      "| 051_truffettes             | 77.454 | 052_acnes_cream              | 69.053 | 053_aveda_conditioner        | 60.495 |\n",
      "| 054_banana_milk_drink      | 76.179 | 055_candle_beast             | 77.888 | 056_china_persimmon          | 83.911 |\n",
      "| 057_danisa_butter_cookies  | 73.242 | 058_effaclar_duo             | 56.699 | 059_evelom_cleanser          | 61.439 |\n",
      "| 060_glasses_box_blone      | 76.125 | 061_handcream_iris           | 51.314 | 062_handcream_lavender       | 43.784 |\n",
      "| 063_handcream_rosewater    | 62.746 | 064_handcream_summer_hill    | 45.680 | 065_hr_serum                 | 71.148 |\n",
      "| 066_japanese_chocolate     | 84.171 | 067_kerastase_hair_treatment | 68.118 | 068_kiehls_serum             | 67.380 |\n",
      "| 069_korean_beef_marinade   | 76.962 | 070_korean_doenjang          | 82.108 | 071_korean_gochujang         | 77.422 |\n",
      "| 072_korean_ssamjang        | 82.805 | 073_loccitane_soap           | 73.738 | 074_marvis_toothpaste_purple | 58.853 |\n",
      "| 075_mouse_thinkpad         | 74.152 | 076_oatly_chocolate          | 68.471 | 077_oatly_original           | 70.551 |\n",
      "| 078_ousa_grated_cheese     | 78.616 | 079_polaroid_film            | 74.663 | 080_skinceuticals_be         | 72.475 |\n",
      "| 081_skinceuticals_cf       | 57.840 | 082_skinceuticals_phyto      | 69.996 | 083_stapler_black            | 71.103 |\n",
      "| 084_stapler_blue           | 73.218 | 085_sunscreen_blue           | 55.782 | 086_tempo_pocket_tissue      | 66.815 |\n",
      "| 087_thermos_flask_purple   | 79.890 | 088_uha_matcha               | 65.801 | 089_urban_decay_spray        | 70.047 |\n",
      "| 090_vitaboost_multivitamin | 71.486 | 091_watercolor_penbox        | 63.270 | 092_youthlt_bilberry_complex | 64.371 |\n",
      "| 093_daiso_mod_remover      | 58.045 | 094_kaneyo_kitchen_bleach    | 67.204 | 095_lays_chip_bag_blue       | 71.637 |\n",
      "| 096_lays_chip_bag_green    | 73.238 | 097_lays_chip_tube_auburn    | 80.764 | 098_lays_chip_tube_green     | 79.855 |\n",
      "| 099_mug_blue               | 67.349 |                              |        |                              |        |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/15 17:51:41 d2.engine.defaults]: \u001b[0mEvaluation results for coco_realDB_val in csv format:\n",
      "\u001b[32m[03/15 17:51:41 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[03/15 17:51:41 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[03/15 17:51:41 d2.evaluation.testing]: \u001b[0mcopypaste: 70.3013,89.6472,83.4352,60.9623,74.7306,84.9185\n"
     ]
    }
   ],
   "source": [
    "# Datasets\n",
    "cfg.DATASETS.TRAIN = ('coco_realDB_train',)\n",
    "cfg.DATASETS.TEST = ('coco_realDB_val',)\n",
    "cfg.DATALOADER.NUM_WORKERS = 0\n",
    "\n",
    "# Output_dir\n",
    "cfg.OUTPUT_DIR = \"./exp_on_FasterRCNN\"\n",
    "\n",
    "# call default Trainer and Predictor for FasterRCNN\n",
    "from nerfdet.engine.train_net import Trainer\n",
    "\n",
    "# train on train_data with inference on val data\n",
    "trainer = Trainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "if cfg.TEST.AUG.ENABLED:\n",
    "    trainer.register_hooks(\n",
    "        [hooks.EvalHook(0, lambda: trainer.test_with_TTA(cfg, trainer.model))]\n",
    "    )\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference on FasterRCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/15 19:37:52 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from exp_on_FasterRCNN_0/model_FasterRCNN.pth ...\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/15 19:37:52 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using configs, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[03/15 19:37:52 d2.data.datasets.coco]: \u001b[0mLoaded 160 images in COCO format from /home/SQQ/svid/NeRFDetExps/Data/annotations/instances_test_8.json\n",
      "\u001b[32m[03/15 19:37:52 d2.data.build]: \u001b[0mDistribution of instances among all 100 categories:\n",
      "\u001b[36m|   category    | #instances   |   category    | #instances   |   category    | #instances   |\n",
      "|:-------------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|\n",
      "| 000_aveda_s.. | 35           | 001_binder_.. | 55           | 002_binder_.. | 50           |\n",
      "| 003_bombik_.. | 42           | 004_bonne_m.. | 24           | 005_bonne_m.. | 25           |\n",
      "| 006_bonne_m.. | 22           | 007_costa_c.. | 52           | 008_essenti.. | 41           |\n",
      "| 009_garlic_.. | 27           | 010_handcre.. | 26           | 011_hb_calc.. | 49           |\n",
      "| 012_hb_grap.. | 45           | 013_hb_mari.. | 46           | 014_hellman.. | 31           |\n",
      "| 015_illy_bl.. | 38           | 016_japanes.. | 26           | 017_john_we.. | 31           |\n",
      "| 018_kerasta.. | 29           | 019_kiehls_.. | 37           | 020_kiihne_.. | 27           |\n",
      "| 021_kiihne_.. | 27           | 022_lindor_.. | 75           | 023_lindor_.. | 75           |\n",
      "| 024_lush_mask | 11           | 025_pasta_s.. | 30           | 026_pasta_s.. | 30           |\n",
      "|   027_pepsi   | 39           | 028_portabl.. | 28           | 029_selfile.. | 52           |\n",
      "| 030_sour_le.. | 41           | 031_sticky_.. | 64           | 032_stridex.. | 38           |\n",
      "| 033_thermos.. | 37           | 034_thermos.. | 54           | 035_thermos.. | 44           |\n",
      "| 036_tragata.. | 25           | 037_tulip_l.. | 34           | 038_unichar.. | 37           |\n",
      "| 039_vinda_t.. | 81           | 040_wrigley.. | 37           | 041_basebal.. | 33           |\n",
      "| 042_basebal.. | 27           | 043_bfe_fac.. | 39           | 044_corgi_d.. | 52           |\n",
      "| 045_dinosau.. | 48           | 046_geo_mocha | 28           | 047_geo_roa.. | 27           |\n",
      "| 048_instant.. | 25           | 049_instant.. | 27           | 050_nabati_.. | 37           |\n",
      "| 051_truffet.. | 35           | 052_acnes_c.. | 15           | 053_aveda_c.. | 20           |\n",
      "| 054_banana_.. | 37           | 055_candle_.. | 22           | 056_china_p.. | 20           |\n",
      "| 057_danisa_.. | 45           | 058_effacla.. | 14           | 059_evelom_.. | 19           |\n",
      "| 060_glasses.. | 36           | 061_handcre.. | 21           | 062_handcre.. | 12           |\n",
      "| 063_handcre.. | 19           | 064_handcre.. | 22           | 065_hr_serum  | 15           |\n",
      "| 066_japanes.. | 22           | 067_kerasta.. | 24           | 068_kiehls_.. | 16           |\n",
      "| 069_korean_.. | 11           | 070_korean_.. | 7            | 071_korean_.. | 8            |\n",
      "| 072_korean_.. | 9            | 073_loccita.. | 20           | 074_marvis_.. | 19           |\n",
      "| 075_mouse_t.. | 41           | 076_oatly_c.. | 31           | 077_oatly_o.. | 35           |\n",
      "| 078_ousa_gr.. | 16           | 079_polaroi.. | 50           | 080_skinceu.. | 11           |\n",
      "| 081_skinceu.. | 11           | 082_skinceu.. | 15           | 083_stapler.. | 27           |\n",
      "| 084_stapler.. | 43           | 085_sunscre.. | 15           | 086_tempo_p.. | 22           |\n",
      "| 087_thermos.. | 29           | 088_uha_mat.. | 27           | 089_urban_d.. | 35           |\n",
      "| 090_vitaboo.. | 15           | 091_waterco.. | 52           | 092_youthlt.. | 11           |\n",
      "| 093_daiso_m.. | 22           | 094_kaneyo_.. | 22           | 095_lays_ch.. | 16           |\n",
      "| 096_lays_ch.. | 19           | 097_lays_ch.. | 24           | 098_lays_ch.. | 23           |\n",
      "| 099_mug_blue  | 10           |               |              |               |              |\n",
      "|     total     | 3070         |               |              |               |              |\u001b[0m\n",
      "\u001b[32m[03/15 19:37:52 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(0, 0), max_size=1024, sample_style='choice')]\n",
      "\u001b[32m[03/15 19:37:52 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common.NumpySerializedList'>\n",
      "\u001b[32m[03/15 19:37:52 d2.data.common]: \u001b[0mSerializing 160 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[03/15 19:37:52 d2.data.common]: \u001b[0mSerialized dataset takes 0.44 MiB\n",
      "\u001b[32m[03/15 19:37:52 d2.evaluation.evaluator]: \u001b[0mStart inference on 160 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/SQQ/anaconda3/envs/svid/lib/python3.8/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1659484810403/work/aten/src/ATen/native/TensorShape.cpp:2894.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[03/15 19:37:55 d2.evaluation.evaluator]: \u001b[0mInference done 11/160. Dataloading: 0.0070 s/iter. Inference: 0.0294 s/iter. Eval: 0.0002 s/iter. Total: 0.0366 s/iter. ETA=0:00:05\n",
      "\u001b[32m[03/15 19:38:00 d2.evaluation.evaluator]: \u001b[0mInference done 143/160. Dataloading: 0.0083 s/iter. Inference: 0.0293 s/iter. Eval: 0.0002 s/iter. Total: 0.0379 s/iter. ETA=0:00:00\n",
      "\u001b[32m[03/15 19:38:01 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:05.829168 (0.037608 s / iter per device, on 1 devices)\n",
      "\u001b[32m[03/15 19:38:01 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:04 (0.029143 s / iter per device, on 1 devices)\n",
      "\u001b[32m[03/15 19:38:01 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[03/15 19:38:01 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output_on_FasterRCNN/coco_instances_results.json\n",
      "\u001b[32m[03/15 19:38:01 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[03/15 19:38:01 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[03/15 19:38:01 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.34 seconds.\n",
      "\u001b[32m[03/15 19:38:01 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[03/15 19:38:01 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.22 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.195\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.292\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.233\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.094\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.298\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.419\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.256\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.275\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.275\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.142\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.395\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.449\n",
      "\u001b[32m[03/15 19:38:01 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:------:|:------:|\n",
      "| 19.541 | 29.205 | 23.261 | 9.417 | 29.798 | 41.948 |\n",
      "\u001b[32m[03/15 19:38:01 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category                   | AP     | category                     | AP     | category                     | AP     |\n",
      "|:---------------------------|:-------|:-----------------------------|:-------|:-----------------------------|:-------|\n",
      "| 000_aveda_shampoo          | 36.885 | 001_binder_clips_median      | 20.471 | 002_binder_clips_small       | 28.024 |\n",
      "| 003_bombik_bucket          | 7.917  | 004_bonne_maman_blueberry    | 1.502  | 005_bonne_maman_raspberry    | 6.882  |\n",
      "| 006_bonne_maman_strawberry | 0.180  | 007_costa_caramel            | 34.654 | 008_essential_oil_bergamot   | 34.629 |\n",
      "| 009_garlic_toast_spread    | 6.040  | 010_handcream_avocado        | 0.073  | 011_hb_calcium               | 15.842 |\n",
      "| 012_hb_grapeseed           | 11.019 | 013_hb_marine_collagen       | 15.033 | 014_hellmanns_mayonnaise     | 8.110  |\n",
      "| 015_illy_blend             | 2.347  | 016_japanese_finger_cookies  | 2.059  | 017_john_west_canned_tuna    | 7.902  |\n",
      "| 018_kerastase_shampoo      | 14.147 | 019_kiehls_facial_cream      | 23.307 | 020_kiihne_balsamic          | 25.294 |\n",
      "| 021_kiihne_honey_mustard   | 28.254 | 022_lindor_matcha            | 34.276 | 023_lindor_salted_caramel    | 20.093 |\n",
      "| 024_lush_mask              | 61.831 | 025_pasta_sauce_black_pepper | 3.859  | 026_pasta_sauce_tomato       | 8.370  |\n",
      "| 027_pepsi                  | 49.619 | 028_portable_yogurt_machine  | 14.389 | 029_selfile_stick            | 4.451  |\n",
      "| 030_sour_lemon_drops       | 3.677  | 031_sticky_notes             | 11.001 | 032_stridex_green            | 50.687 |\n",
      "| 033_thermos_flask_cream    | 26.929 | 034_thermos_flask_muji       | 5.988  | 035_thermos_flask_sliver     | 1.540  |\n",
      "| 036_tragata_olive_oil      | 16.378 | 037_tulip_luncheon_meat      | 3.899  | 038_unicharm_cotton_pad      | 44.583 |\n",
      "| 039_vinda_tissue           | 45.063 | 040_wrigley_doublemint_gum   | 0.114  | 041_baseball_cap_black       | 26.560 |\n",
      "| 042_baseball_cap_pink      | 43.955 | 043_bfe_facial_mask          | 18.989 | 044_corgi_doll               | 34.572 |\n",
      "| 045_dinosaur_doll          | 47.138 | 046_geo_mocha                | 2.397  | 047_geo_roast_charcoal       | 5.965  |\n",
      "| 048_instant_noodle_black   | 3.551  | 049_instant_noodle_red       | 28.552 | 050_nabati_cheese_wafer      | 27.831 |\n",
      "| 051_truffettes             | 10.060 | 052_acnes_cream              | 18.231 | 053_aveda_conditioner        | 38.137 |\n",
      "| 054_banana_milk_drink      | 11.310 | 055_candle_beast             | 28.949 | 056_china_persimmon          | 31.966 |\n",
      "| 057_danisa_butter_cookies  | 5.227  | 058_effaclar_duo             | 14.998 | 059_evelom_cleanser          | 37.165 |\n",
      "| 060_glasses_box_blone      | 30.015 | 061_handcream_iris           | 0.099  | 062_handcream_lavender       | 0.000  |\n",
      "| 063_handcream_rosewater    | 3.392  | 064_handcream_summer_hill    | 0.000  | 065_hr_serum                 | 31.893 |\n",
      "| 066_japanese_chocolate     | 34.053 | 067_kerastase_hair_treatment | 19.215 | 068_kiehls_serum             | 39.765 |\n",
      "| 069_korean_beef_marinade   | 41.179 | 070_korean_doenjang          | 9.109  | 071_korean_gochujang         | 0.000  |\n",
      "| 072_korean_ssamjang        | 14.733 | 073_loccitane_soap           | 47.125 | 074_marvis_toothpaste_purple | 55.916 |\n",
      "| 075_mouse_thinkpad         | 3.271  | 076_oatly_chocolate          | 27.426 | 077_oatly_original           | 28.422 |\n",
      "| 078_ousa_grated_cheese     | 5.286  | 079_polaroid_film            | 3.333  | 080_skinceuticals_be         | 42.603 |\n",
      "| 081_skinceuticals_cf       | 38.906 | 082_skinceuticals_phyto      | 21.782 | 083_stapler_black            | 17.066 |\n",
      "| 084_stapler_blue           | 18.141 | 085_sunscreen_blue           | 14.084 | 086_tempo_pocket_tissue      | 0.344  |\n",
      "| 087_thermos_flask_purple   | 27.048 | 088_uha_matcha               | 10.331 | 089_urban_decay_spray        | 22.087 |\n",
      "| 090_vitaboost_multivitamin | 28.102 | 091_watercolor_penbox        | 0.111  | 092_youthlt_bilberry_complex | 0.000  |\n",
      "| 093_daiso_mod_remover      | 23.385 | 094_kaneyo_kitchen_bleach    | 45.477 | 095_lays_chip_bag_blue       | 27.619 |\n",
      "| 096_lays_chip_bag_green    | 18.300 | 097_lays_chip_tube_auburn    | 12.268 | 098_lays_chip_tube_green     | 19.309 |\n",
      "| 099_mug_blue               | 0.000  |                              |        |                              |        |\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('bbox',\n",
       "              {'AP': 19.540672844834543,\n",
       "               'AP50': 29.205249682984284,\n",
       "               'AP75': 23.260544483677727,\n",
       "               'APs': 9.417337681406377,\n",
       "               'APm': 29.797716613569612,\n",
       "               'APl': 41.94837340876945,\n",
       "               'AP-000_aveda_shampoo': 36.885054653867314,\n",
       "               'AP-001_binder_clips_median': 20.471351482974384,\n",
       "               'AP-002_binder_clips_small': 28.023668778088666,\n",
       "               'AP-003_bombik_bucket': 7.916666666666666,\n",
       "               'AP-004_bonne_maman_blueberry': 1.5023142347515304,\n",
       "               'AP-005_bonne_maman_raspberry': 6.882088208820882,\n",
       "               'AP-006_bonne_maman_strawberry': 0.1798256748751798,\n",
       "               'AP-007_costa_caramel': 34.6542185463134,\n",
       "               'AP-008_essential_oil_bergamot': 34.628817449160906,\n",
       "               'AP-009_garlic_toast_spread': 6.03960396039604,\n",
       "               'AP-010_handcream_avocado': 0.07295466388744137,\n",
       "               'AP-011_hb_calcium': 15.842382734514054,\n",
       "               'AP-012_hb_grapeseed': 11.019116404394062,\n",
       "               'AP-013_hb_marine_collagen': 15.03312810272624,\n",
       "               'AP-014_hellmanns_mayonnaise': 8.109618104667609,\n",
       "               'AP-015_illy_blend': 2.346534653465347,\n",
       "               'AP-016_japanese_finger_cookies': 2.0594059405940595,\n",
       "               'AP-017_john_west_canned_tuna': 7.902329021364234,\n",
       "               'AP-018_kerastase_shampoo': 14.147119552375312,\n",
       "               'AP-019_kiehls_facial_cream': 23.30697091737618,\n",
       "               'AP-020_kiihne_balsamic': 25.293885157746544,\n",
       "               'AP-021_kiihne_honey_mustard': 28.253852696193988,\n",
       "               'AP-022_lindor_matcha': 34.27620065131541,\n",
       "               'AP-023_lindor_salted_caramel': 20.092578022732994,\n",
       "               'AP-024_lush_mask': 61.830504479019325,\n",
       "               'AP-025_pasta_sauce_black_pepper': 3.8587841977475055,\n",
       "               'AP-026_pasta_sauce_tomato': 8.370290946145307,\n",
       "               'AP-027_pepsi': 49.61916407529049,\n",
       "               'AP-028_portable_yogurt_machine': 14.389438943894387,\n",
       "               'AP-029_selfile_stick': 4.451382655479792,\n",
       "               'AP-030_sour_lemon_drops': 3.6771966625936,\n",
       "               'AP-031_sticky_notes': 11.001215787436324,\n",
       "               'AP-032_stridex_green': 50.68672930795142,\n",
       "               'AP-033_thermos_flask_cream': 26.928971157985366,\n",
       "               'AP-034_thermos_flask_muji': 5.988415168047418,\n",
       "               'AP-035_thermos_flask_sliver': 1.54015401540154,\n",
       "               'AP-036_tragata_olive_oil': 16.378005657708623,\n",
       "               'AP-037_tulip_luncheon_meat': 3.8994668697639,\n",
       "               'AP-038_unicharm_cotton_pad': 44.58278829081863,\n",
       "               'AP-039_vinda_tissue': 45.06317342569714,\n",
       "               'AP-040_wrigley_doublemint_gum': 0.11424219345011423,\n",
       "               'AP-041_baseball_cap_black': 26.559881714124227,\n",
       "               'AP-042_baseball_cap_pink': 43.95531123404919,\n",
       "               'AP-043_bfe_facial_mask': 18.98892494832054,\n",
       "               'AP-044_corgi_doll': 34.57191667011463,\n",
       "               'AP-045_dinosaur_doll': 47.137862452642395,\n",
       "               'AP-046_geo_mocha': 2.3969888568172926,\n",
       "               'AP-047_geo_roast_charcoal': 5.964970921644595,\n",
       "               'AP-048_instant_noodle_black': 3.551259887893552,\n",
       "               'AP-049_instant_noodle_red': 28.55172692255468,\n",
       "               'AP-050_nabati_cheese_wafer': 27.830887597486313,\n",
       "               'AP-051_truffettes': 10.060429133572697,\n",
       "               'AP-052_acnes_cream': 18.23078736445073,\n",
       "               'AP-053_aveda_conditioner': 38.13670314399861,\n",
       "               'AP-054_banana_milk_drink': 11.310184961747874,\n",
       "               'AP-055_candle_beast': 28.949186935500283,\n",
       "               'AP-056_china_persimmon': 31.966488956587963,\n",
       "               'AP-057_danisa_butter_cookies': 5.226953482952519,\n",
       "               'AP-058_effaclar_duo': 14.998307523060001,\n",
       "               'AP-059_evelom_cleanser': 37.16519907692408,\n",
       "               'AP-060_glasses_box_blone': 30.014614098772512,\n",
       "               'AP-061_handcream_iris': 0.09900990099009901,\n",
       "               'AP-062_handcream_lavender': 0.0,\n",
       "               'AP-063_handcream_rosewater': 3.3917348256564783,\n",
       "               'AP-064_handcream_summer_hill': 0.0,\n",
       "               'AP-065_hr_serum': 31.893463736617566,\n",
       "               'AP-066_japanese_chocolate': 34.052614876872305,\n",
       "               'AP-067_kerastase_hair_treatment': 19.214515969869414,\n",
       "               'AP-068_kiehls_serum': 39.76531653165317,\n",
       "               'AP-069_korean_beef_marinade': 41.17938264414678,\n",
       "               'AP-070_korean_doenjang': 9.108910891089108,\n",
       "               'AP-071_korean_gochujang': 0.0,\n",
       "               'AP-072_korean_ssamjang': 14.732673267326735,\n",
       "               'AP-073_loccitane_soap': 47.124801501456616,\n",
       "               'AP-074_marvis_toothpaste_purple': 55.91588570621768,\n",
       "               'AP-075_mouse_thinkpad': 3.2710396039603964,\n",
       "               'AP-076_oatly_chocolate': 27.425719347328624,\n",
       "               'AP-077_oatly_original': 28.421658503786855,\n",
       "               'AP-078_ousa_grated_cheese': 5.285778577857785,\n",
       "               'AP-079_polaroid_film': 3.3333333333333326,\n",
       "               'AP-080_skinceuticals_be': 42.602545968882595,\n",
       "               'AP-081_skinceuticals_cf': 38.90594059405941,\n",
       "               'AP-082_skinceuticals_phyto': 21.782178217821784,\n",
       "               'AP-083_stapler_black': 17.065821378056174,\n",
       "               'AP-084_stapler_blue': 18.14067741714291,\n",
       "               'AP-085_sunscreen_blue': 14.084158415841582,\n",
       "               'AP-086_tempo_pocket_tissue': 0.34369111747501757,\n",
       "               'AP-087_thermos_flask_purple': 27.048267326732674,\n",
       "               'AP-088_uha_matcha': 10.330749441225462,\n",
       "               'AP-089_urban_decay_spray': 22.087454525503702,\n",
       "               'AP-090_vitaboost_multivitamin': 28.102310231023097,\n",
       "               'AP-091_watercolor_penbox': 0.11126826968411126,\n",
       "               'AP-092_youthlt_bilberry_complex': 0.0,\n",
       "               'AP-093_daiso_mod_remover': 23.385043174647134,\n",
       "               'AP-094_kaneyo_kitchen_bleach': 45.47717170984498,\n",
       "               'AP-095_lays_chip_bag_blue': 27.618811881188115,\n",
       "               'AP-096_lays_chip_bag_green': 18.299890333860976,\n",
       "               'AP-097_lays_chip_tube_auburn': 12.268088347296269,\n",
       "               'AP-098_lays_chip_tube_green': 19.30918091809181,\n",
       "               'AP-099_mug_blue': 0.0})])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Datasets\n",
    "cfg.DATASETS.TEST = ('coco_realDB_test',)  # set test data\n",
    "cfg.DATALOADER.NUM_WORKERS = 0\n",
    "cfg.INPUT.MAX_SIZE_TEST = 1024\n",
    "cfg.INPUT.MIN_SIZE_TEST = 0\n",
    "\n",
    "# Load trained weights\n",
    "cfg.MODEL.WEIGHTS = os.path.join(\"exp_on_FasterRCNN\", \"model_final.pth\")  # path to the model we just trained\n",
    "\n",
    "from detectron2.engine import DefaultPredictor\n",
    "\n",
    "predictor = DefaultPredictor(cfg)\n",
    "evaluator = COCOEvaluator(\"coco_realDB_test\", cfg, False, output_dir=\"./output_on_FasterRCNN\")\n",
    "test_loader = build_detection_test_loader(cfg, \"coco_realDB_test\")\n",
    "inference_on_dataset(predictor.model, test_loader, evaluator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
